{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run WES-QC pipeline\n",
    "\n",
    "This Jupyter notebook runs all steps for WES-QC pipeline.\n",
    "It supports both running in an SSH mode (on a local machine with remote access to the cluster) or directly from the remote cluster head node.\n",
    "\n",
    "Fir details explaining the steps, see the documentation in the `docs/wes-qc-hail.md`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with jupyter notebook on the local machine\n",
    "\n",
    "1. First, prepare a python environment with a Jupyter server. There is no additional dependency to install.\n",
    "A quick way to do this is to install `uv` - `curl -LsSf https://astral.sh/uv/install.sh | sh`, see [uv](https://astral.sh/uv/) for more details.\n",
    "Then run `uv add jupyterlab`, the `jupyter` executable will be installed in `.venv/bin/jupyter`.\n",
    "\n",
    "2. Then, set up an SSH connection to the cluster, for example, if the cluster IP address is `172.27.1.1`, add the following to your `~/.ssh/config` file:\n",
    "```\n",
    "Host wes\n",
    "    HostName 172.27.1.1\n",
    "    User ubuntu\n",
    "    IdentityFile ~/.ssh/id_rsa\n",
    "```\n",
    "id_rsa is the private key for accessing the cluster when the cluster was created.\n",
    "\n",
    "3. Then, in the python environment, run the following command to start the notebook:\n",
    "```\n",
    "jupyter notebook scripts/run-wes-qc-pipeline-all-steps.ipynb\n",
    "```\n",
    "or if you are using VSCode, you can open the notebook directly in VSCode and set the Python interpreter to the one with the Jupyter notebook installed.\n",
    "\n",
    "4. Follow the instructions in the notebook to run the steps.\n",
    "Note that the variable `jupyter_notebook_on_cluster` needs to be set to `False` in the notebook.\n",
    "\n",
    "**Warning:** if you run the notebook in SSH mode, your computer runs a local jupyter server to execute commands and track the progress.\n",
    "If your computer loses connection to the cluster head node due to any network issues (or, for example, when your computer goes to sleep), the data processing terminates.\n",
    "\n",
    "\n",
    "### Run with jupyter notebook on the cluster\n",
    "\n",
    "1. First, prepare a python environment with Jupyter notebook installed, same as above.\n",
    "See the above [Run with jupyter notebook on the local machine](#run-with-jupyter-notebook-on-the-local-machine) section for more details.\n",
    "\n",
    "2. Then, start a jupyter notebook server on the cluster:\n",
    "```\n",
    "jupyter notebook --no-browser --port=8889 scripts/run-wes-qc-pipeline-all-steps.ipynb\n",
    "```\n",
    "Note for clusters created by the Sangeyou cannot use the default port 8888 because it is already used by the built-in notebook server on the master node.\n",
    "The built-in notebook server on the master node is not suitable because its Spark will claim all the resources and the pipeline will not be able to run.\n",
    "\n",
    "If you are using VSCode, you can open the notebook directly in VSCode and set the python interpreter to the system python.\n",
    "\n",
    "3. Follow the instructions in the notebook to run the pipeline.\n",
    "Note that the variable `jupyter_notebook_on_cluster` needs to be set to `True` in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T13:52:57.145127Z",
     "start_time": "2025-02-27T13:52:57.142606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set this to `True` if you want to execute this jupyter notebook on the cluster head node.\n",
    "jupyter_notebook_on_cluster = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T13:52:58.249667Z",
     "start_time": "2025-02-27T13:52:58.246770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T13:52:59.009040Z",
     "start_time": "2025-02-27T13:52:59.005712Z"
    }
   },
   "outputs": [],
   "source": [
    "# The small function to run command either via SSH (for local run)\n",
    "# or directly (when the notebook is on cluster)\n",
    "def run_cmd(cmd):\n",
    "    if jupyter_notebook_on_cluster:\n",
    "        !{cmd}\n",
    "    else:\n",
    "        !ssh -o StrictHostKeyChecking=no wes \"{cmd}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T13:52:59.992734Z",
     "start_time": "2025-02-27T13:52:59.989553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function that runs a series of scripts\n",
    "def run_step_scripts(step_folder, scripts):\n",
    "    for script, prefix in scripts.items():\n",
    "        print(\"=\" * 120 + \"\\n\")\n",
    "        logger.info(f\"Running {script}\")\n",
    "        cmd = f\"cd {path_to_wes} && ./scripts/hlrun_local --prefix={prefix} {step_folder}/{script}\"\n",
    "        run_cmd(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the path to the wes-qc directory\n",
    "\n",
    "All WES-QC repo should be located on the cluster head node).\n",
    "Make sure the config/inputs.yaml symlinks to the correct dataset config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T13:53:19.294883Z",
     "start_time": "2025-02-27T13:53:19.292281Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_wes = \"/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Check Hail is working on the cluster"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T13:53:32.057616Z",
     "start_time": "2025-02-27T13:53:21.967995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\r\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\r\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1353-0.2.133-4c60fddb171a.log\r\n"
     ]
    }
   ],
   "source": [
    "python = \"/home/ubuntu/venv/bin/python\"\n",
    "cmd = (\n",
    "    f'cd {path_to_wes}; {python} -c \\\\\"import hail as hl; hl.init()\\\\\" '\n",
    "    if not jupyter_notebook_on_cluster\n",
    "    else f'cd {path_to_wes}; {python} -c \"import hail as hl; hl.init()\" '\n",
    ")\n",
    "run_cmd(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to configure run steps\n",
    "To configure run steps you only need to set up a dictionaly describing the step.\n",
    "Dictionary key is the command to run (with arguments if they are required), the value is the name of the log file.\n",
    "This notebook automatically collects all logs form the running steps.\n",
    "\n",
    "\n",
    "### Step 0 - Resource Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T13:45:52.404211Z",
     "start_time": "2025-02-25T13:43:45.638637Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 13:43:45,640 - INFO - Running 1-import_1kg.py --all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 0-resource_preparation/1-import_1kg.py --all\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/0-resource_preparation\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/0-resource_preparation/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250225-1343-0.2.133-4c60fddb171a.log\r\n",
      "Loading VCFs from file:///lustre/scratch126/teams/hgi/gz3/public-dataset/resources/mini_1000G\r\n",
      "2025-02-25 13:44:04.948 Hail: INFO: Reading table without type imputation1) / 1]\r\n",
      "  Loading field 'Sample name' as type str (not specified)\r\n",
      "  Loading field 'Sex' as type str (not specified)\r\n",
      "  Loading field 'Biosample ID' as type str (not specified)\r\n",
      "  Loading field 'Population code' as type str (not specified)\r\n",
      "  Loading field 'Population name' as type str (not specified)\r\n",
      "  Loading field 'Superpopulation code' as type str (not specified)\r\n",
      "  Loading field 'Superpopulation name' as type str (not specified)\r\n",
      "  Loading field 'Population elastic ID' as type str (not specified)\r\n",
      "  Loading field 'Data collections' as type str (not specified)\r\n",
      "Saving as hail mt to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/kg_unprocessed.mt\r\n",
      "2025-02-25 13:44:07.392 Hail: INFO: scanning VCF for sortedness...  (0 + 1) / 1]\r\n",
      "2025-02-25 13:44:20.804 Hail: INFO: Coerced prefix-sorted VCF, requiring additional sorting within data partitions on each query.\r\n",
      "2025-02-25 13:45:24.991 Hail: INFO: wrote matrix table with 1004437 rows and 150 columns in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/kg_unprocessed.mt\r\n",
      "2025-02-25 13:45:26.825 Hail: INFO: Reading table without type imputation\r\n",
      "  Loading field 'f0' as type str (user-supplied)\r\n",
      "  Loading field 'f1' as type int32 (user-supplied)\r\n",
      "  Loading field 'f2' as type int32 (user-supplied)\r\n",
      "  Loading field 'f3' as type str (user-supplied)\r\n",
      "2025-02-25 13:45:27.352 Hail: INFO: ld_prune: running local pruning stage with max queue size of 762601 variants\r\n",
      "2025-02-25 13:45:38.754 Hail: INFO: Coerced sorted dataset          (0 + 1) / 1]\r\n",
      "^Ctage 10:>                                                         (0 + 1) / 1]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 13:45:45,605 - INFO - Running 2-generate-truthset-ht.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 0-resource_preparation/2-generate-truthset-ht.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/0-resource_preparation\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/0-resource_preparation/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "step0 = {\"1-import_1kg.py --all\": \"0-1-import-1kg\", \"2-generate-truthset-ht.py\": \"0-2-generate-truthset-ht\"}\n",
    "step0_folder = \"0-resource_preparation\"\n",
    "run_step_scripts(step0_folder, step0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Step 1 - Import Data"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T10:18:35.168223Z",
     "start_time": "2025-02-26T10:15:51.339905Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 10:15:51,341 - INFO - Running 1-import_gatk_vcfs_to_hail.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 1-import_data/1-import_gatk_vcfs_to_hail.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/1-import_data\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/1-import_data/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250226-1015-0.2.133-4c60fddb171a.log\r\n",
      "info: Found 1 VCFs in /lustre/scratch126/teams/hgi/gz3/public-dataset/test_data_from_1000_genomes\r\n",
      "info: Loading VCFs WITHOUT header\r\n",
      "Saving as hail mt to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/gatk_unprocessed.mt\r\n",
      "2025-02-26 10:16:06.436 Hail: INFO: scanning VCF for sortedness...\r\n",
      "2025-02-26 10:16:15.260 Hail: INFO: Coerced sorted VCF - no additional import work to do\r\n",
      "2025-02-26 10:16:43.768 Hail: INFO: wrote matrix table with 566135 rows and 111 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/gatk_unprocessed.mt\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 10:16:45,081 - INFO - Running 2-import_annotations.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 1-import_data/2-import_annotations.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/1-import_data\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/1-import_data/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250226-1016-0.2.133-4c60fddb171a.log\r\n",
      "=== Running verifyBamID validation \r\n",
      "2025-02-26 10:17:04.199 Hail: INFO: Reading table without type imputation1) / 1]\r\n",
      "  Loading field '#SEQ_ID' as type str (user-supplied)\r\n",
      "  Loading field 'RG' as type str (user-supplied)\r\n",
      "  Loading field 'CHIP_ID' as type str (user-supplied)\r\n",
      "  Loading field '#SNPS' as type int32 (user-supplied)\r\n",
      "  Loading field '#READS' as type int32 (user-supplied)\r\n",
      "  Loading field 'AVG_DP' as type float64 (user-supplied)\r\n",
      "  Loading field 'FREEMIX' as type float64 (user-supplied)\r\n",
      "  Loading field 'FREELK1' as type float64 (user-supplied)\r\n",
      "  Loading field 'FREELK0' as type float64 (user-supplied)\r\n",
      "  Loading field 'FREE_RH' as type str (user-supplied)\r\n",
      "  Loading field 'FREE_RA' as type str (user-supplied)\r\n",
      "  Loading field 'CHIPMIX' as type str (user-supplied)\r\n",
      "  Loading field 'CHIPLK1' as type str (user-supplied)\r\n",
      "  Loading field 'CHIPLK0' as type str (user-supplied)\r\n",
      "  Loading field 'CHIP_RH' as type str (user-supplied)\r\n",
      "  Loading field 'CHIP_RA' as type str (user-supplied)\r\n",
      "  Loading field 'DPREF' as type str (user-supplied)\r\n",
      "  Loading field 'RDPHET' as type str (user-supplied)\r\n",
      "  Loading field 'RDPALT' as type str (user-supplied)\r\n",
      "2025-02-26 10:17:04.221 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\r\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\r\n",
      "2025-02-26 10:17:10.554 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-26 10:17:12.540 Hail: INFO: merging 29 files totalling 80...\r\n",
      "2025-02-26 10:17:12.748 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/samples_failing_freemix.tsv\r\n",
      "  merge time: 207.368ms\r\n",
      "=== 1 samples failed freemix\r\n",
      "=== Failing samples exported to /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/samples_failing_freemix.tsv\r\n",
      "=== WARNING: Detected 1 samples without freemix: 2025-02-26 10:17:14.729 Hail: INFO: Coerced sorted dataset\r\n",
      "HG00610.alt_bwamem_GRCh38DH.20150826.CHS.exome\r\n",
      "2025-02-26 10:17:15.985 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "=== Annotating self-reported sex \r\n",
      "2025-02-26 10:17:17.743 Hail: INFO: Reading table without type imputation\r\n",
      "  Loading field 'sample_id' as type str (not specified)\r\n",
      "  Loading field 'self_reported_sex' as type str (not specified)\r\n",
      "=== WARNING: Detected 111 samples without self-reported sex: 2025-02-26 10:17:19.426 Hail: INFO: Coerced sorted dataset\r\n",
      "HG00272.alt_bwamem_GRCh38DH.20150826.FIN.exome HG00285.alt_bwamem_GRCh38DH.20150826.FIN.exome HG00338.alt_bwamem_GRCh38DH.20150826.FIN.exome HG00406.alt_bwamem_GRCh38DH.20150826.CHS.exome HG00478.alt_bwamem_GRCh38DH.20150826.CHS.exome HG00536.alt_bwamem_GRCh38DH.20150826.CHS.exome HG00551.alt_bwamem_GRCh38DH.20150826.PUR.exome HG00556.alt_bwamem_GRCh38DH.20150826.CHS.exome HG00584.alt_bwamem_GRCh38DH.20150826.CHS.exome HG00592.alt_bwamem_GRCh38DH.20150826.CHS.exome HG00599.alt_bwamem_GRCh38DH.20150826.CHS.exome HG00607.alt_bwamem_GRCh38DH.20150826.CHS.exome HG00610.alt_bwamem_GRCh38DH.20150826.CHS.exome HG00731.alt_bwamem_GRCh38DH.20150826.PUR.exome HG00732.alt_bwamem_GRCh38DH.20150826.PUR.exome HG00733.alt_bwamem_GRCh38DH.20150826.PUR.exome HG00734.alt_bwamem_GRCh38DH.20150826.PUR.exome HG01051.alt_bwamem_GRCh38DH.20150826.PUR.exome HG01101.alt_bwamem_GRCh38DH.20150826.PUR.exome HG01174.alt_bwamem_GRCh38DH.20150826.PUR.exome HG01200.alt_bwamem_GRCh38DH.20150826.PUR.exome HG01325.alt_bwamem_GRCh38DH.20150826.PUR.exome HG01435.alt_bwamem_GRCh38DH.20150826.CLM.exome HG01441.alt_bwamem_GRCh38DH.20150826.CLM.exome HG01465.alt_bwamem_GRCh38DH.20150826.CLM.exome HG01590.alt_bwamem_GRCh38DH.20150826.PJL.exome HG01602.alt_bwamem_GRCh38DH.20150826.IBS.exome HG01612.alt_bwamem_GRCh38DH.20150826.IBS.exome HG01615.alt_bwamem_GRCh38DH.20150826.IBS.exome HG01618.alt_bwamem_GRCh38DH.20150826.IBS.exome HG01794.alt_bwamem_GRCh38DH.20150826.CDX.exome HG01874.alt_bwamem_GRCh38DH.20150826.KHV.exome HG01939.alt_bwamem_GRCh38DH.20150826.PEL.exome HG01958.alt_bwamem_GRCh38DH.20150826.ACB.exome HG01979.alt_bwamem_GRCh38DH.20150826.PEL.exome HG02024.alt_bwamem_GRCh38DH.20150826.KHV.exome HG02025.alt_bwamem_GRCh38DH.20150826.KHV.exome HG02026.alt_bwamem_GRCh38DH.20150826.KHV.exome HG02058.alt_bwamem_GRCh38DH.20150826.KHV.exome HG02078.alt_bwamem_GRCh38DH.20150826.KHV.exome HG02154.alt_bwamem_GRCh38DH.20150826.CDX.exome HG02271.alt_bwamem_GRCh38DH.20150826.PEL.exome HG02274.alt_bwamem_GRCh38DH.20150826.PEL.exome HG02373.alt_bwamem_GRCh38DH.20150826.CDX.exome HG02425.alt_bwamem_GRCh38DH.20150826.PEL.exome HG02682.alt_bwamem_GRCh38DH.20150826.PJL.exome HG02716.alt_bwamem_GRCh38DH.20150826.GWD.exome HG02808.alt_bwamem_GRCh38DH.20150826.GWD.exome HG02881.alt_bwamem_GRCh38DH.20150826.GWD.exome HG02976.alt_bwamem_GRCh38DH.20150826.ESN.exome HG02983.alt_bwamem_GRCh38DH.20150826.GWD.exome HG03097.alt_bwamem_GRCh38DH.20150826.MSL.exome HG03117.alt_bwamem_GRCh38DH.20150826.ESN.exome HG03225.alt_bwamem_GRCh38DH.20150826.MSL.exome HG03363.alt_bwamem_GRCh38DH.20150826.ESN.exome HG03391.alt_bwamem_GRCh38DH.20150826.MSL.exome HG03490.alt_bwamem_GRCh38DH.20150826.PJL.exome HG03619.alt_bwamem_GRCh38DH.20150826.PJL.exome HG03653.alt_bwamem_GRCh38DH.20150826.PJL.exome HG03705.alt_bwamem_GRCh38DH.20150826.PJL.exome HG03720.alt_bwamem_GRCh38DH.20150826.ITU.exome HG03869.alt_bwamem_GRCh38DH.20150826.ITU.exome HG03871.alt_bwamem_GRCh38DH.20150826.ITU.exome HG03885.alt_bwamem_GRCh38DH.20150826.STU.exome HG03941.alt_bwamem_GRCh38DH.20150826.BEB.exome HG04017.alt_bwamem_GRCh38DH.20150826.ITU.exome NA11881.alt_bwamem_GRCh38DH.20150826.CEU.exome NA11994.alt_bwamem_GRCh38DH.20150826.CEU.exome NA12044.alt_bwamem_GRCh38DH.20150826.CEU.exome NA12286.alt_bwamem_GRCh38DH.20150826.CEU.exome NA12287.alt_bwamem_GRCh38DH.20150826.CEU.exome NA12342.alt_bwamem_GRCh38DH.20150826.CEU.exome NA12546.alt_bwamem_GRCh38DH.20150826.CEU.exome NA12827.alt_bwamem_GRCh38DH.20150826.CEU.exome NA18552.alt_bwamem_GRCh38DH.20150826.CHB.exome NA18563.alt_bwamem_GRCh38DH.20150826.CHB.exome NA18794.alt_bwamem_GRCh38DH.20150826.CHB.exome NA18949.alt_bwamem_GRCh38DH.20150826.JPT.exome NA18992.alt_bwamem_GRCh38DH.20150826.JPT.exome NA19025.alt_bwamem_GRCh38DH.20150826.LWK.exome NA19028.alt_bwamem_GRCh38DH.20150826.LWK.exome NA19081.alt_bwamem_GRCh38DH.20150826.JPT.exome NA19197.alt_bwamem_GRCh38DH.20150826.YRI.exome NA19238.alt_bwamem_GRCh38DH.20150826.YRI.exome NA19239.alt_bwamem_GRCh38DH.20150826.YRI.exome NA19240.alt_bwamem_GRCh38DH.20150826.YRI.exome NA19307.alt_bwamem_GRCh38DH.20150826.LWK.exome NA19338.alt_bwamem_GRCh38DH.20150826.LWK.exome NA19379.alt_bwamem_GRCh38DH.20150826.LWK.exome NA19452.alt_bwamem_GRCh38DH.20150826.LWK.exome NA19471.alt_bwamem_GRCh38DH.20150826.LWK.exome NA19684.alt_bwamem_GRCh38DH.20150826.MXL.exome NA19717.alt_bwamem_GRCh38DH.20150826.MXL.exome NA19755.alt_bwamem_GRCh38DH.20150826.MXL.exome NA19758.alt_bwamem_GRCh38DH.20150826.MXL.exome NA19798.alt_bwamem_GRCh38DH.20150826.MXL.exome NA19901.alt_bwamem_GRCh38DH.20150826.ASW.exome NA20535.alt_bwamem_GRCh38DH.20150826.TSI.exome NA20772.alt_bwamem_GRCh38DH.20150826.TSI.exome NA20778.alt_bwamem_GRCh38DH.20150826.TSI.exome NA20807.alt_bwamem_GRCh38DH.20150826.TSI.exome NA20829.alt_bwamem_GRCh38DH.20150826.TSI.exome NA20851.alt_bwamem_GRCh38DH.20150826.GIH.exome NA20853.alt_bwamem_GRCh38DH.20150826.GIH.exome NA20872.alt_bwamem_GRCh38DH.20150826.GIH.exome NA20893.alt_bwamem_GRCh38DH.20150826.GIH.exome NA20903.alt_bwamem_GRCh38DH.20150826.GIH.exome NA21106.alt_bwamem_GRCh38DH.20150826.GIH.exome NA21113.alt_bwamem_GRCh38DH.20150826.GIH.exome NA21115.alt_bwamem_GRCh38DH.20150826.GIH.exome NA21127.alt_bwamem_GRCh38DH.20150826.GIH.exome\r\n",
      "2025-02-26 10:17:31.164 Hail: INFO: wrote matrix table with 566135 rows and 111 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_metadata_annotated.mt\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 10:17:32,456 - INFO - Running 3-validate-gtcheck.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 1-import_data/3-validate-gtcheck.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/1-import_data\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/1-import_data/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250226-1017-0.2.133-4c60fddb171a.log\r\n",
      "\r\n",
      "=== WES data samples validation ===\r\n",
      "Total 111 IDs in WES data data\r\n",
      "111 unique IDs in WES data\r\n",
      "All IDs in WES data are unique\r\n",
      "\r\n",
      "=== MicroARRAY data samples validation ===\r\n",
      "Total 111 IDs in MicroARRAY data data\r\n",
      "111 unique IDs in MicroARRAY data\r\n",
      "All IDs in MicroARRAY data are unique\r\n",
      "\r\n",
      "=== Mapping stats ===\r\n",
      "Total: 112 records in mapping\r\n",
      "110 unique IDs in WES mapping\r\n",
      "1 non-unique IDs in WES mapping\r\n",
      "Non-unique samples dumped to /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/gtcheck/public-dataset.WES_mapping_non-unique.txt\r\n",
      "112 unique IDs in MicroARRAY mapping\r\n",
      "All IDs in MicroARRAY mapping are unique\r\n",
      "\r\n",
      "=== Mapping consistency checking ===\r\n",
      "All WES data IDs present in mapping table\r\n",
      "All WES IDs from mapping exist in data\r\n",
      "1 MicroARRAY IDs from data not present in mapping: /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/gtcheck/public-dataset.MicroARRAY.ids_data_not_in_map.txt\r\n",
      "   --> Including 1 unique IDs, and 0 non-uniqie IDS\r\n",
      "2 MicroARRAY IDs from map not present in data: /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/gtcheck/public-dataset.MicroARRAY.ids_map_not_in_data.txt\r\n",
      "   --> Including 2 unique IDs, and 0 non-uniqie IDS\r\n",
      "\r\n",
      "=== Marking duplicates in ID mapping ===\r\n",
      "Identified 2 samples with non-unique WES<->microarray mapping: /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/gtcheck/public-dataset.non-unique-pairs.csv\r\n",
      "Removing from the mapping all microarray IDs not present in the real microarray data\r\n",
      "Survived unique Array IDs:  110\r\n",
      "Checking mapping ID pairs uniqiness\r\n",
      "ALL WES-microarray pairs are unique.\r\n",
      "Checkin for duplicated ids:  duplicated_id_any\r\n",
      "False    110\r\n",
      "Name: count, dtype: int64\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/1-import_data/3-validate-gtcheck.py:332: SettingWithCopyWarning: \r\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\r\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\r\n",
      "\r\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\r\n",
      "  gtcheck_not_matched_map.loc[:, \"wes_restored_by_best_match\"] = wes_by_best_match.apply(\r\n",
      "=== Passed validation: 108 samples\r\n",
      "validation_tags\r\n",
      "best_match_exist_in_mapfile,best_match_matched_mapfile,mapfile_unique,score_passed,    107\r\n",
      "best_match_not_exist_in_mapfile,                                                         1\r\n",
      "Name: count, dtype: int64\r\n",
      "\r\n",
      "=== Failed validation: 3 samples\r\n",
      "validation_tags\r\n",
      "best_match_exist_in_mapfile,best_match_matched_mapfile,mapfile_unique,score_failed,                    1\r\n",
      "best_match_exist_in_mapfile,best_match_not_matched_mapfile,no_mapfile_pairs_have_gtcheck,              1\r\n",
      "best_match_exist_in_mapfile,best_match_not_matched_mapfile,mapfile_pairs_have_gtcheck,score_failed,    1\r\n",
      "Name: count, dtype: int64\r\n",
      "2025-02-26 10:18:00.813 Hail: INFO: wrote matrix table with 566135 rows and 111 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_gtcheck_validated.mt\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 10:18:02,106 - INFO - Running 4-mutation-spectra_preqc.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 1-import_data/4-mutation-spectra_preqc.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/1-import_data\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/1-import_data/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250226-1018-0.2.133-4c60fddb171a.log\r\n",
      "2025-02-26 10:18:16.091 Hail: WARN: entries(): Resulting entries table is sorted by '(row_key, col_key)'.\r\n",
      "    To preserve row-major matrix table order, first unkey columns with 'key_cols_by()'\r\n",
      "2025-02-26 10:18:25.413 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "[Stage 2:===================>                                       (1 + 2) / 3]\r"
     ]
    }
   ],
   "source": [
    "step1 = {\n",
    "    \"1-import_gatk_vcfs_to_hail.py\": \"1-1-import_gatk_vcfs_to_hail\",\n",
    "    \"2-import_annotations.py\": \"1-2-import_annotations\",\n",
    "    \"3-validate-gtcheck.py\": \"1-3-validate-gtcheck\",\n",
    "    \"4-mutation-spectra_preqc.py\": \"1-4-mutation-spectra_preqc\",\n",
    "}\n",
    "step1_folder = \"1-import_data\"\n",
    "run_step_scripts(step1_folder, step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Sample QC\n",
    "\n",
    "The SampleQC step is pretty automated and mostly produced acceptable results even with the default set of parameters.\n",
    "However, we strongly advise you to refer to the documentation, review the metrics plots and tune filtering thresholds if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T13:43:17.552151Z",
     "start_time": "2025-02-26T10:21:41.772597Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 10:21:41,777 - INFO - Running 1-hard_filters_sex_annotation.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 2-sample_qc/1-hard_filters_sex_annotation.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/2-sample_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/2-sample_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250226-1021-0.2.133-4c60fddb171a.log\r\n",
      "Reading input matrix\r\n",
      "=== Applying hard filters before sex prediction ===\r\n",
      "===Imputing sex ===\r\n",
      "2025-02-26 10:21:57.764 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\r\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\r\n",
      "2025-02-26 10:22:21.750 Hail: INFO: Coerced sorted dataset        (20 + 8) / 28]\r\n",
      "2025-02-26 10:22:22.639 Hail: INFO: merging 29 files totalling 5.9K...\r\n",
      "2025-02-26 10:22:23.057 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/sex_annotated.sex_check.tsv.bgz\r\n",
      "  merge time: 416.764ms\r\n",
      "2025-02-26 10:22:38.738 Hail: INFO: Coerced sorted dataset          (2 + 1) / 3]\r\n",
      "2025-02-26 10:22:39.152 Hail: INFO: merging 29 files totalling 1.7K...\r\n",
      "2025-02-26 10:22:39.453 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/sex_annotation_f_stat_outliers.tsv\r\n",
      "  merge time: 300.454ms\r\n",
      "--- Writing to /lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_sex_annotated.mt\r\n",
      "2025-02-26 10:23:07.636 Hail: INFO: wrote matrix table with 313294 rows and 111 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_sex_annotated.mt\r\n",
      "Annotating samples with inconsistencies:\r\n",
      "2025-02-26 10:23:26.062 Hail: INFO: Coerced sorted dataset          (2 + 1) / 3]\r\n",
      "2025-02-26 10:23:26.469 Hail: INFO: merging 29 files totalling 85...\r\n",
      "2025-02-26 10:23:26.657 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/conflicting_sex.tsv\r\n",
      "  merge time: 187.325ms\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 10:23:28,054 - INFO - Running 2-prune_related_samples.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 2-sample_qc/2-prune_related_samples.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/2-sample_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/2-sample_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250226-1023-0.2.133-4c60fddb171a.log\r\n",
      "=== Filtering to autosomes\r\n",
      "=== Splitting multiallelic sites\r\n",
      "=== Performing LD pruning\r\n",
      "2025-02-26 10:23:43.086 Hail: INFO: ld_prune: running local pruning stage with max queue size of 860371 variants\r\n",
      "2025-02-26 10:23:57.983 Hail: INFO: wrote table with 106794 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_TablefOd5biyl20\r\n",
      "2025-02-26 10:23:59.683 Hail: INFO: wrote table with 106794 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/zcp8dREnpSObT6mNH0Sd3q\r\n",
      "2025-02-26 10:24:14.055 Hail: INFO: wrote matrix with 106794 rows and 111 columns as 27 blocks of size 4096 to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/Zb4141QKoaw88WqXe12VhK\r\n",
      "2025-02-26 10:24:39.693 Hail: INFO: wrote table with 80 rows in 53 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/uTGPRWUaJ19xVvkplRq4Xo\r\n",
      "2025-02-26 10:24:42.628 Hail: INFO: wrote table with 106733 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_Tableoa4gbVspTl\r\n",
      "2025-02-26 10:24:48.696 Hail: INFO: wrote matrix table with 106733 rows and 111 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_ldpruned.mt\r\n",
      "=== Running PC relate\r\n",
      "2025-02-26 10:24:53.923 Hail: INFO: hwe_normalize: found 106733 variants after filtering out monomorphic sites.\r\n",
      "2025-02-26 10:25:00.389 Hail: INFO: pca: running PCA with 3 components...1) / 3]\r\n",
      "2025-02-26 10:25:22.182 Hail: INFO: wrote table with 0 rows in 0 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_TableH03KAgwruQ\r\n",
      "=== Calculating relatedness\r\n",
      "2025-02-26 10:25:31.557 Hail: INFO: wrote matrix with 106733 rows and 111 columns as 27 blocks of size 4096 to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/VVsPWLy84MWrpTz0HuS230\r\n",
      "2025-02-26 10:25:32.844 Hail: INFO: wrote matrix with 4 rows and 106733 columns as 27 blocks of size 4096 to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/pcrelate-write-read-WY8zXuSs43wqO4ExgJdFRM.bm\r\n",
      "2025-02-26 10:25:33.214 Hail: INFO: wrote matrix with 106733 rows and 111 columns as 27 blocks of size 4096 to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/pcrelate-write-read-hpWbVFuVqaGhzqBPJlRilp.bm\r\n",
      "2025-02-26 10:25:33.587 Hail: INFO: wrote matrix with 106733 rows and 111 columns as 27 blocks of size 4096 to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/pcrelate-write-read-b3dauqZu6XLU03XBRZKQcI.bm\r\n",
      "2025-02-26 10:25:35.677 Hail: INFO: wrote matrix with 111 rows and 111 columns as 1 block of size 4096 to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/pcrelate-write-read-gg9fe6nIWVsRo3gPvznoQp.bm\r\n",
      "2025-02-26 10:25:37.088 Hail: INFO: wrote matrix with 111 rows and 111 columns as 1 block of size 4096 to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/pcrelate-write-read-LSHD3wuTK8VUrNfjQjlVc7.bm\r\n",
      "2025-02-26 10:25:37.792 Hail: INFO: wrote matrix with 111 rows and 111 columns as 1 block of size 4096 to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/pcrelate-write-read-zpUdwHD4mS5P0LYGjJKQiu.bm\r\n",
      "2025-02-26 10:25:41.266 Hail: INFO: wrote matrix with 111 rows and 111 columns as 1 block of size 4096 to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/pcrelate-write-read-5MzyutjQwdB803NqHMODTf.bm\r\n",
      "2025-02-26 10:25:42.191 Hail: INFO: wrote matrix with 111 rows and 111 columns as 1 block of size 4096 to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/pcrelate-write-read-yd9yKYQkapvS765locNY3q.bm\r\n",
      "2025-02-26 10:25:42.863 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-26 10:25:44.069 Hail: INFO: wrote table with 136 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_Tables5VnTlTz0Y\r\n",
      "2025-02-26 10:25:44.890 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:25:45.307 Hail: INFO: wrote table with 25 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_Tablecuk3kQD8SN\r\n",
      "2025-02-26 10:25:45.705 Hail: INFO: wrote table with 4 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/uQ1RWda6fzLC2RjSaIvFSW\r\n",
      "2025-02-26 10:25:46.103 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:25:46.535 Hail: INFO: wrote table with 111 rows in 28 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_pruned.pca_scores.ht\r\n",
      "2025-02-26 10:25:46.973 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:25:47.335 Hail: INFO: wrote table with 2 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_related_samples_to_remove.ht\r\n",
      "2025-02-26 10:25:47.717 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:25:48.027 Hail: INFO: merging 2 files totalling 115...\r\n",
      "2025-02-26 10:25:48.054 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/related_samples_to_remove.tsv\r\n",
      "  merge time: 25.802ms\r\n",
      "2025-02-26 10:25:48.255 Hail: INFO: merging 2 files totalling 568...\r\n",
      "2025-02-26 10:25:48.285 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/relatedness.tsv.gz\r\n",
      "  merge time: 29.723ms\r\n",
      "=== Running population PCA\r\n",
      "=== Removing related samples\r\n",
      "2025-02-26 10:25:49.843 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\r\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\r\n",
      "2025-02-26 10:25:50.999 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:25:51.258 Hail: INFO: Coerced sorted dataset\r\n",
      "=== Survived 109 samples after relatedness step.                    (0 + 3) / 3]\r\n",
      "2025-02-26 10:25:56.929 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:25:57.109 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:25:58.469 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:25:58.647 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:25:59.988 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:00.194 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:01.539 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:01.719 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:03.021 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:03.198 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:08.964 Hail: INFO: merging 4 files totalling 2.9M...2 + 1) / 3]\r\n",
      "2025-02-26 10:26:09.132 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_unrelated.plink.bed\r\n",
      "  merge time: 167.531ms\r\n",
      "2025-02-26 10:26:09.142 Hail: INFO: merging 3 files totalling 4.2M...\r\n",
      "2025-02-26 10:26:09.296 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_unrelated.plink.bim\r\n",
      "  merge time: 153.171ms\r\n",
      "=== Running PCA\r\n",
      "2025-02-26 10:26:10.181 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:10.356 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:15.274 Hail: INFO: hwe_normalize: found 106719 variants after filtering out monomorphic sites.\r\n",
      "2025-02-26 10:26:16.324 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:16.536 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:22.579 Hail: INFO: pca: running PCA with 4 components...3) / 3]\r\n",
      "2025-02-26 10:26:40.254 Hail: INFO: Coerced sorted dataset          (1 + 2) / 3]\r\n",
      "WARNING: An illegal reflective access operation has occurred\r\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/opt/spark/jars/spark-core_2.12-3.5.3.jar) to field java.util.concurrent.locks.ReentrantReadWriteLock.readerLock\r\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\r\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\r\n",
      "WARNING: All illegal access operations will be denied in a future release\r\n",
      "2025-02-26 10:26:44.249 Hail: INFO: wrote table with 106719 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_TableTLvYAK2mRw\r\n",
      "=== Plotting PC1 vs PC2\r\n",
      "2025-02-26 10:26:45.372 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:45.554 Hail: INFO: Coerced sorted dataset\r\n",
      "=== Saving Relatedness PCA plot to /lustre/scratch126/teams/hgi/gz3/public-dataset/plots/pca.html\r\n",
      "2025-02-26 10:26:47.053 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:47.211 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:52.931 Hail: INFO: wrote matrix table with 106733 rows and 109 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_pca.mt\r\n",
      "2025-02-26 10:26:53.267 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:53.626 Hail: INFO: wrote table with 109 rows in 28 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_pca_scores.ht\r\n",
      "2025-02-26 10:26:54.455 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:54.618 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:26:59.823 Hail: INFO: wrote table with 106719 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_pca_loadings.ht\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 10:27:01,150 - INFO - Running 3-population_pca_prediction.py --all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 2-sample_qc/3-population_pca_prediction.py --all\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/2-sample_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/2-sample_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250226-1027-0.2.133-4c60fddb171a.log\r\n",
      "2025-02-26 10:27:22.848 Hail: INFO: Reading table without type imputation1) / 1]\r\n",
      "  Loading field 'f0' as type str (user-supplied)\r\n",
      "  Loading field 'f1' as type int32 (user-supplied)\r\n",
      "  Loading field 'f2' as type int32 (user-supplied)\r\n",
      "  Loading field 'f3' as type str (user-supplied)\r\n",
      "2025-02-26 10:27:30.174 Hail: INFO: Coerced sorted dataset          (2 + 1) / 3]\r\n",
      "2025-02-26 10:27:31.016 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:27:47.515 Hail: INFO: wrote matrix table with 763 rows and 261 columns in 1 partition to /lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/merged_with_1kg_filtered.mt\r\n",
      "2025-02-26 10:27:48.384 Hail: INFO: ld_prune: running local pruning stage with max queue size of 578525 variants\r\n",
      "2025-02-26 10:27:50.618 Hail: INFO: wrote table with 334 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_Table5RBMzdYPaY\r\n",
      "2025-02-26 10:27:53.085 Hail: INFO: wrote table with 334 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/8sjxTXD28tMfeSn1xgEtnq\r\n",
      "2025-02-26 10:27:56.993 Hail: INFO: wrote matrix with 334 rows and 261 columns as 1 block of size 4096 to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/lSsh7HDBfdH43Sqvt29U0H\r\n",
      "2025-02-26 10:28:02.867 Hail: INFO: wrote table with 0 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/6WZbUNfIA7fpGFdl5NjMkP\r\n",
      "2025-02-26 10:28:04.412 Hail: INFO: wrote table with 334 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_TableVNK8Ht3cv0\r\n",
      "2025-02-26 10:28:07.378 Hail: INFO: wrote matrix table with 334 rows and 261 columns in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/merged_with_1kg_filtered_ldpruned.mt\r\n",
      "2025-02-26 10:28:08.214 Hail: INFO: hwe_normalize: found 333 variants after filtering out monomorphic sites.\r\n",
      "2025-02-26 10:28:09.212 Hail: INFO: pca: running PCA with 4 components...\r\n",
      "2025-02-26 10:28:17.700 Hail: INFO: Coerced sorted dataset          (0 + 1) / 1]\r\n",
      "WARNING: An illegal reflective access operation has occurred\r\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/opt/spark/jars/spark-core_2.12-3.5.3.jar) to field java.util.concurrent.locks.ReentrantReadWriteLock.readerLock\r\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\r\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\r\n",
      "WARNING: All illegal access operations will be denied in a future release\r\n",
      "2025-02-26 10:28:21.639 Hail: INFO: wrote table with 333 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_TableVWk5X1zgfa\r\n",
      "2025-02-26 10:28:21.761 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\r\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\r\n",
      "=== Projecting PCA scores to the cohort samples ===\r\n",
      "2025-02-26 10:28:22.954 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-26 10:28:23.357 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:28:25.680 Hail: INFO: wrote table with 150 rows in 28 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/pop_pca_1kg_scores.ht\r\n",
      "2025-02-26 10:28:26.713 Hail: INFO: wrote table with 333 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/pop_pca_1kg_loadings.ht\r\n",
      "2025-02-26 10:28:28.597 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-26 10:28:28.984 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:28:29.190 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:28:31.567 Hail: INFO: wrote table with 261 rows in 56 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/pop_pca_union_scores.ht\r\n",
      "Plotting PCA components for file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/pop_pca_union_scores.ht\r\n",
      "Union components: 261\r\n",
      "Plotting PCA components for file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/pop_pca_1kg_scores.ht\r\n",
      "1kg components: 150\r\n",
      "2025-02-26 10:28:36.883 Hail: INFO: Reading table without type imputation\r\n",
      "  Loading field 'Sample name' as type str (not specified)\r\n",
      "  Loading field 'Sex' as type str (not specified)\r\n",
      "  Loading field 'Biosample ID' as type str (not specified)\r\n",
      "  Loading field 'Population code' as type str (not specified)\r\n",
      "  Loading field 'Population name' as type str (not specified)\r\n",
      "  Loading field 'Superpopulation code' as type str (not specified)\r\n",
      "  Loading field 'Superpopulation name' as type str (not specified)\r\n",
      "  Loading field 'Population elastic ID' as type str (not specified)\r\n",
      "  Loading field 'Data collections' as type str (not specified)\r\n",
      "2025-02-26 10:28:37.434 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-26 10:28:38.798 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-26 10:28:40.203 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "INFO (gnomad.sample_qc.ancestry 346): Random forest feature importances are as follows: [0.26697026 0.36810814 0.26095891 0.10396269]\r\n",
      "INFO (gnomad.sample_qc.ancestry 356): Estimated error rate for RF model is 0.0333\r\n",
      "INFO (gnomad.sample_qc.ancestry 371): Found the following sample count after population assignment: EUR: 50, EAS: 54, AMR: 48, AFR: 54, SAS: 51, oth: 4\r\n",
      "2025-02-26 10:28:43.945 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:28:44.944 Hail: INFO: Coerced sorted dataset\r\n",
      "2025-02-26 10:28:45.956 Hail: INFO: wrote table with 261 rows in 28 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/pop_assignments.ht\r\n",
      "Plotting PCA components for assigned populations: file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/pop_assignments.ht\r\n",
      "Total samples: 261\r\n",
      "Plotting PCA components for the dataset:\r\n",
      "Total samples: 111\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 10:28:50,822 - INFO - Running 4-find_population_outliers.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 2-sample_qc/4-find_population_outliers.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/2-sample_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/2-sample_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250226-1028-0.2.133-4c60fddb171a.log\r\n",
      "2025-02-26 10:29:22.174 Hail: INFO: wrote matrix table with 566135 rows and 111 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/gatk_unprocessed_with_pop.mt\r\n",
      "Filtering input MT by depth: DP=20, genotype quality: GQ=20, VAF: VAF=0.25\r\n",
      "Filtering 26.82% entries out of downstream analysis.                (2 + 1) / 3]\r\n",
      "2025-02-26 10:29:29.057 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\r\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\r\n",
      "2025-02-26 10:29:41.152 Hail: INFO: Coerced sorted dataset       (12 + 16) / 28]\r\n",
      "2025-02-26 10:29:42.478 Hail: INFO: wrote table with 111 rows in 28 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/compute_stratified_metrics_filter-1CWn4nykRFKZfK3UT5woBk.ht\r\n",
      "2025-02-26 10:30:03.704 Hail: INFO: Coerced sorted dataset          (1 + 2) / 3]\r\n",
      "2025-02-26 10:30:05.963 Hail: INFO: wrote table with 111 rows in 28 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_Tablem7RRcAETke\r\n",
      "=== Samples passing pop filtering: 104\r\n",
      "2025-02-26 10:30:29.821 Hail: INFO: wrote matrix table with 553183 rows and 111 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_pops_sampleqc.mt\r\n",
      "2025-02-26 10:30:41.137 Hail: INFO: Coerced sorted dataset          (1 + 2) / 3]\r\n",
      "2025-02-26 10:30:42.159 Hail: INFO: wrote table with 111 rows in 28 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_pops_sampleqc.ht\r\n",
      "2025-02-26 10:30:43.211 Hail: INFO: wrote table with 111 rows in 28 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_pops_QC_filters.ht\r\n",
      "2025-02-26 10:30:43.628 Hail: INFO: merging 29 files totalling 27.6K...\r\n",
      "2025-02-26 10:30:44.025 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/sample_qc_by_pop.tsv.bgz\r\n",
      "  merge time: 396.265ms\r\n",
      "2025-02-26 10:30:44.399 Hail: INFO: merging 2 files totalling 5.9K...\r\n",
      "2025-02-26 10:30:44.426 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/sample_qc_by_pop.globals.json\r\n",
      "  merge time: 26.964ms\r\n",
      "=== Plotting population metrics ===\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-26 10:31:53,490 - INFO - Running 5-filter_fail_sample_qc.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 2-sample_qc/5-filter_fail_sample_qc.py\r\n",
      "Read from remote host 172.27.25.130: Connection reset by peer\r\n",
      "client_loop: send disconnect: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "step2 = {\n",
    "    \"1-hard_filters_sex_annotation.py\": \"2-1-hard-filters-sex-annotation\",\n",
    "    \"2-prune_related_samples.py\": \"2-2-prune-related-samples\",\n",
    "    \"3-population_pca_prediction.py --all\": \"2-3-population-pca-prediction\",\n",
    "    \"4-find_population_outliers.py\": \"2-4-find-population-outliers\",\n",
    "    \"5-filter_fail_sample_qc.py\": \"2-5-filter-fail-sample-qc\",\n",
    "}\n",
    "step2_folder = \"2-sample_qc\"\n",
    "run_step_scripts(step2_folder, step2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Variant QC \n",
    "The first part of the VariantQC step - before training the random forest model.\n",
    "Don't forget to set the RF model ID you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T11:25:03.725412Z",
     "start_time": "2025-02-27T11:02:38.941913Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 11:02:38,944 - INFO - Running 1-split_and_family_annotate.py --all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 3-variant_qc/1-split_and_family_annotate.py --all\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1102-0.2.133-4c60fddb171a.log\r\n",
      "2025-02-27 11:03:09.602 Hail: INFO: wrote matrix table with 566135 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_varqc.mt\r\n",
      "Annotating entries with allele balance\r\n",
      "Annotating variants with mean allele balance\r\n",
      "writing split mt\r\n",
      "2025-02-27 11:03:40.782 Hail: INFO: wrote matrix table with 579395 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_varqc_splitmulti.mt\r\n",
      "=== Reading pedifree: /lustre/scratch126/teams/hgi/gz3/public-dataset/metadata/test_1000g_v2.triosonly.ped\r\n",
      "2025-02-27 11:03:42.408 Hail: INFO: Coerced sorted dataset        (24 + 4) / 28]\r\n",
      "2025-02-27 11:03:42.410 Hail: INFO: Coerced dataset with out-of-order partitions.\r\n",
      "2025-02-27 11:03:43.050 Hail: INFO: Coerced sorted dataset========(28 + 4) / 28]\r\n",
      "2025-02-27 11:03:43.051 Hail: INFO: Coerced dataset with out-of-order partitions.\r\n",
      "=== Total pedigree records:  3====================================(28 + 1) / 28]\r\n",
      "=== Total samples:  9\r\n",
      "2025-02-27 11:03:54.196 Hail: INFO: wrote matrix table with 579395 rows and 3 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/trios.mt\r\n",
      "=== Extracted 3 full trios ===\r\n",
      "WARNING (gnomad.sample_qc.relatedness 1103): Since no proband sex expression was given to generate_trio_stats_expr, only DNMs in autosomes will be counted.\r\n",
      "WARNING (gnomad.sample_qc.relatedness 1103): Since no proband sex expression was given to generate_trio_stats_expr, only DNMs in autosomes will be counted.\r\n",
      "2025-02-27 11:04:02.943 Hail: INFO: wrote table with 565940 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/trio_stats.ht\r\n",
      "=== Generating family stats ===\r\n",
      "2025-02-27 11:04:03.833 Hail: INFO: Reading table without type imputation\r\n",
      "  Loading field 'f0' as type str (not specified)\r\n",
      "  Loading field 'f1' as type str (not specified)\r\n",
      "  Loading field 'f2' as type str (not specified)\r\n",
      "  Loading field 'f3' as type str (not specified)\r\n",
      "  Loading field 'f4' as type str (not specified)\r\n",
      "  Loading field 'f5' as type str (not specified)\r\n",
      "2025-02-27 11:04:11.929 Hail: INFO: wrote table with 579237 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_TablepZmWGSioC6\r\n",
      "2025-02-27 11:04:12.167 Hail: WARN: entries(): Resulting entries table is sorted by '(row_key, col_key)'.\r\n",
      "    To preserve row-major matrix table order, first unkey columns with 'key_cols_by()'\r\n",
      "2025-02-27 11:04:23.427 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/family_stats.ht\r\n",
      "2025-02-27 11:04:46.524 Hail: INFO: wrote matrix table with 579395 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/family_stats.mt\r\n",
      "2025-02-27 11:12:07.657 Hail: INFO: wrote matrix table with 579395 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/family_stats_gnomad.mt\r\n",
      "2025-02-27 11:21:49.906 Hail: INFO: wrote table with 617 rows in 480 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/denovo_table.ht\r\n",
      "2025-02-27 11:21:56.631 Hail: INFO: wrote table with 566135 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/inbreeding.ht\r\n",
      "2025-02-27 11:22:01.525 Hail: INFO: wrote table with 566135 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/qc_ac.ht\r\n",
      "2025-02-27 11:22:09.045 Hail: INFO: wrote table with 594726 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/allele_data.ht\r\n",
      "[Stage 22:==========================================================(3 + 1) / 3]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 11:22:10,271 - INFO - Running 2-create_rf_ht.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 3-variant_qc/2-create_rf_ht.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1122-0.2.133-4c60fddb171a.log\r\n",
      "pedfile:  /lustre/scratch126/teams/hgi/gz3/public-dataset/metadata/test_1000g_v2.triosonly.ped\r\n",
      "--- Annotation with trio stats ---\r\n",
      "INFO (gnomad.variant_qc.random_forest 176): Computing feature medians for imputation of missing numeric values\r\n",
      "INFO (gnomad.variant_qc.random_forest 196): Variant count by strata:(1 + 2) / 3]\r\n",
      "('indel',): 39654\r\n",
      "('mixed',): 8213\r\n",
      "('multi-indel',): 30843\r\n",
      "('multi-snv',): 4727\r\n",
      "('snv',): 495958\r\n",
      "WARNING: An illegal reflective access operation has occurred========(3 + 1) / 3]\r\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/opt/spark/jars/spark-core_2.12-3.5.3.jar) to field java.util.concurrent.locks.ReentrantReadWriteLock.readerLock\r\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\r\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\r\n",
      "WARNING: All illegal access operations will be denied in a future release\r\n",
      "2025-02-27 11:23:07.396 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/ht_for_RF_by_variant_type_all_cols.ht\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 11:23:08,594 - INFO - Running 3-train_rf.py --manual-model-id test-run-model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 3-variant_qc/3-train_rf.py --manual-model-id test-run-model\r\n",
      "!!! WARNING !!!\r\n",
      "The gnomAD fucntion train_rf_model() in some cases\r\n",
      "could work incorrectly in the parallel SPARK environment.\r\n",
      "\r\n",
      "If the run of the function will fail with some weird message\r\n",
      "(no space left on device, wrong imports, etc),\r\n",
      "try running model training on the master node only:\r\n",
      "\r\n",
      "PYTHONPATH=$(pwd):$PYTHONPATH PYSPARK_DRIVER_PYTHON=/home/ubuntu/venv/bin/python spark-submit --master local[*]  3-variant_qc/3-train_rf.py\r\n",
      "\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1123-0.2.133-4c60fddb171a.log\r\n",
      "File file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest could not be found. Returning empty RF run hash dict.\r\n",
      "Using provided run ID: test-run-model\r\n",
      "test_intervals\r\n",
      "chr20\r\n",
      "Resulting intervals\r\n",
      "[Interval(start=Locus(contig=chr20, position=1, reference_genome=GRCh38), end=Locus(contig=chr20, position=64444167, reference_genome=GRCh38), includes_start=True, includes_end=True)]\r\n",
      "2025-02-27 11:23:28.386 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_Table9ssA16aZTu\r\n",
      "2025-02-27 11:23:31.620 Hail: INFO: wrote table with 351947 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_TableqWyjbsOYYc\r\n",
      "2025-02-27 11:23:37.923 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "WARNING: An illegal reflective access operation has occurred\r\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/opt/spark/jars/spark-core_2.12-3.5.3.jar) to field java.util.regex.Pattern.pattern\r\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\r\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\r\n",
      "WARNING: All illegal access operations will be denied in a future release\r\n",
      "INFO (gnomad.variant_qc.training 81):    contig     tp     fp      n     ti    tv  indel\r\n",
      "0    chr1  False   True   3856   1386  1672    798\r\n",
      "1    chr1   True  False  31819  22174  8207   1438\r\n",
      "2    chr1   True   True    119     46    58     15\r\n",
      "3   chr10  False   True   1513    577   579    357\r\n",
      "4   chr10   True  False  13693   9427  3626    640\r\n",
      "..    ...    ...    ...    ...    ...   ...    ...\r\n",
      "63   chrX  False   True   1213    379   525    309\r\n",
      "64   chrX   True  False   6127   4295  1711    121\r\n",
      "65   chrX   True   True      7      3     2      2\r\n",
      "66   chrY  False   True     55     28    17     10\r\n",
      "67   chrY   True  False     20     17     3      0\r\n",
      "\r\n",
      "[68 rows x 7 columns]\r\n",
      "INFO (gnomad.variant_qc.training 101): Training examples sampling: tp=0.102550*309877, fp=1.000000*31778\r\n",
      "INFO (gnomad.variant_qc.pipeline 447): Summary of TP/FP and RF training data:\r\n",
      "2025-02-27 11:23:43.101 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "+------+-------+----------+----------+---------+--------+           (1 + 2) / 3]\r\n",
      "|  _tp |   _fp | rf_train | rf_label | rf_test |      n |\r\n",
      "+------+-------+----------+----------+---------+--------+\r\n",
      "| bool |  bool |     bool | str      |    bool |  int64 |\r\n",
      "+------+-------+----------+----------+---------+--------+\r\n",
      "| True | False |    False | \"TP\"     |   False | 277970 |\r\n",
      "| True | False |    False | \"TP\"     |    True |   8615 |\r\n",
      "| True | False |     True | \"TP\"     |   False |  31907 |\r\n",
      "| True |  True |    False | NA       |   False |   1046 |\r\n",
      "| True |  True |    False | NA       |    True |     13 |\r\n",
      "|   NA | False |       NA | NA       |   False | 222084 |\r\n",
      "|   NA | False |       NA | NA       |    True |   5364 |\r\n",
      "|   NA |  True |    False | \"FP\"     |    True |    618 |\r\n",
      "|   NA |  True |     True | \"FP\"     |   False |  31778 |\r\n",
      "+------+-------+----------+----------+---------+--------+\r\n",
      "\r\n",
      "INFO (gnomad.variant_qc.pipeline 450): Training RF model:\r\n",
      "features: variant_type,allele_type,n_alt_alleles,was_mixed,was_split,has_star,MQ,QD,MQRankSum,SOR,ReadPosRankSum,meanHetAB\r\n",
      "num_tree: 500\r\n",
      "max_depth:5\r\n",
      "INFO (gnomad.variant_qc.random_forest 449): Training RF model using:\r\n",
      "features: variant_type,allele_type,n_alt_alleles,was_mixed,was_split,has_star,MQ,QD,MQRankSum,SOR,ReadPosRankSum,meanHetAB\r\n",
      "labels: rf_label\r\n",
      "num_trees: 500\r\n",
      "max_depth: 5\r\n",
      "INFO (gnomad.variant_qc.random_forest 468): Found labels: ['TP', 'FP'] + 2) / 3]\r\n",
      "INFO (gnomad.variant_qc.random_forest 472): Indexing string features: variant_type,allele_type\r\n",
      "INFO (gnomad.variant_qc.random_forest 507): Training RF model=>     (2 + 1) / 3]\r\n",
      "INFO (gnomad.variant_qc.random_forest 512): RF features importance: (2 + 1) / 3]\r\n",
      "variant_type: 0.0017787856454632269\r\n",
      "allele_type: 0.0027087436803584024\r\n",
      "n_alt_alleles: 0.0006448111851739145\r\n",
      "was_mixed: 1.2767627642990725e-05\r\n",
      "was_split: 0.011429352312490025\r\n",
      "has_star: 0.0052220557443415395\r\n",
      "MQ: 0.2547656234066734\r\n",
      "QD: 0.3802316604054792\r\n",
      "MQRankSum: 0.02422082871694901\r\n",
      "SOR: 0.0663926652629319\r\n",
      "ReadPosRankSum: 0.009066729870078484\r\n",
      "meanHetAB: 0.24352597614241775\r\n",
      "INFO (gnomad.variant_qc.pipeline 467): Testing model on specified variants or intervals...\r\n",
      "INFO (gnomad.variant_qc.random_forest 353): Applying RF model.\r\n",
      "2025-02-27 11:24:50.541 Hail: INFO: Coerced sorted dataset          (0 + 1) / 1]\r\n",
      "2025-02-27 11:24:51.250 Hail: INFO: Coerced sorted dataset          (0 + 2) / 2]\r\n",
      "2025-02-27 11:24:52.254 Hail: INFO: Coerced sorted dataset          (0 + 1) / 1]\r\n",
      "INFO (gnomad.variant_qc.random_forest 324): Testing results:        (0 + 1) / 1]\r\n",
      "rf_prediction   FP    TP\r\n",
      "rf_label                \r\n",
      "FP             615     3\r\n",
      "TP              51  8564\r\n",
      "INFO (gnomad.variant_qc.random_forest 325): Accuracy: 0.994151\r\n",
      "Writing out ht_training data\r\n",
      "2025-02-27 11:24:57.413 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/test-run-model/training.ht\r\n",
      "Saving runs info in /lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/rf_runs.json\r\n",
      "\r\n",
      "=== test-run-model ===\r\n",
      "{\r\n",
      "    \"features_importance\": {\r\n",
      "        \"MQ\": 0.2547656234066734,\r\n",
      "        \"MQRankSum\": 0.02422082871694901,\r\n",
      "        \"QD\": 0.3802316604054792,\r\n",
      "        \"ReadPosRankSum\": 0.009066729870078484,\r\n",
      "        \"SOR\": 0.0663926652629319,\r\n",
      "        \"allele_type\": 0.0027087436803584024,\r\n",
      "        \"has_star\": 0.0052220557443415395,\r\n",
      "        \"meanHetAB\": 0.24352597614241775,\r\n",
      "        \"n_alt_alleles\": 0.0006448111851739145,\r\n",
      "        \"variant_type\": 0.0017787856454632269,\r\n",
      "        \"was_mixed\": 1.2767627642990725e-05,\r\n",
      "        \"was_split\": 0.011429352312490025\r\n",
      "    },\r\n",
      "    \"input_args\": {\r\n",
      "        \"adj\": true,\r\n",
      "        \"transmitted_singletons\": true,\r\n",
      "        \"vqsr_training\": false\r\n",
      "    },\r\n",
      "    \"test_accuracy\": 0.9941514134084263,\r\n",
      "    \"test_intervals\": \"chr20\"\r\n",
      "}\r\n",
      "INFO (gnomad.variant_qc.random_forest 597): Testing results:\r\n",
      "rf_prediction   FP    TP\r\n",
      "rf_label                \r\n",
      "FP             615     3\r\n",
      "TP              51  8564\r\n",
      "INFO (gnomad.variant_qc.random_forest 414): Saving model to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/test-run-model/rf.model\r\n",
      "[Stage 62:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "model_id = \"test-run-model\"\n",
    "\n",
    "step3_1 = {\n",
    "    \"1-split_and_family_annotate.py --all\": \"3-1-split_and_family_annotate\",\n",
    "    \"2-create_rf_ht.py\": \"3-2-create-rf-ht\",\n",
    "    f\"3-train_rf.py --manual-model-id {model_id}\": \"3-3-train-rf\",\n",
    "}\n",
    "step3_folder = \"3-variant_qc\"\n",
    "run_step_scripts(step3_folder, step3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Changing the model run ID in the config file"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T10:20:58.914909Z",
     "start_time": "2025-02-27T10:20:57.916348Z"
    }
   },
   "outputs": [],
   "source": [
    "yaml_file = \"config/inputs.yaml\"\n",
    "cmd = f\"sed --follow-symlinks -i 's/rf_model_id:.*/rf_model_id: {model_id}/' {path_to_wes}/{yaml_file}\"\n",
    "run_cmd(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the second part of the VariantQC. Please ferer to the docs (`docs/wes-qc-hail.md`) for details.\n",
    "\n",
    "After finishing the variant QC process, you need to review the results and choose hardfilters for the genotype filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T12:40:14.277434Z",
     "start_time": "2025-02-27T12:28:19.894301Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:28:19,897 - INFO - Running 4-apply_rf.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 3-variant_qc/4-apply_rf.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1228-0.2.133-4c60fddb171a.log\r\n",
      "INFO (gnomad.variant_qc.random_forest 428): Loading model from file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/test-run-model/rf.model\r\n",
      "INFO (gnomad.variant_qc.random_forest 353): Applying RF model.      (0 + 1) / 1]\r\n",
      "2025-02-27 12:29:45.037 Hail: INFO: Coerced sorted dataset          (2 + 1) / 3]\r\n",
      "2025-02-27 12:29:47.558 Hail: INFO: Coerced sorted dataset          (2 + 2) / 3]\r\n",
      "2025-02-27 12:29:47.559 Hail: INFO: Coerced dataset with out-of-order partitions.\r\n",
      "2025-02-27 12:29:49.681 Hail: INFO: Coerced sorted dataset          (2 + 2) / 3]\r\n",
      "2025-02-27 12:29:49.682 Hail: INFO: Coerced dataset with out-of-order partitions.\r\n",
      "2025-02-27 12:29:52.516 Hail: INFO: Coerced sorted dataset          (2 + 2) / 3]\r\n",
      "2025-02-27 12:29:52.517 Hail: INFO: Coerced dataset with out-of-order partitions.\r\n",
      "2025-02-27 12:29:54.918 Hail: INFO: Coerced sorted dataset          (2 + 1) / 3]\r\n",
      "2025-02-27 12:29:58.308 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/test-run-model/rf_result.ht\r\n",
      "2025-02-27 12:29:59.400 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "+------+-------+----------+----------+---------------+--------+\r\n",
      "|   tp |    fp | rf_train | rf_label | rf_prediction |      n |\r\n",
      "+------+-------+----------+----------+---------------+--------+\r\n",
      "| bool |  bool |     bool | str      | str           |  int64 |\r\n",
      "+------+-------+----------+----------+---------------+--------+\r\n",
      "| True | False |    False | \"TP\"     | \"FP\"          |   2744 |\r\n",
      "| True | False |    False | \"TP\"     | \"TP\"          | 283841 |\r\n",
      "| True | False |     True | \"TP\"     | \"FP\"          |    289 |\r\n",
      "| True | False |     True | \"TP\"     | \"TP\"          |  31618 |\r\n",
      "| True |  True |    False | NA       | \"FP\"          |   1046 |\r\n",
      "| True |  True |    False | NA       | \"TP\"          |     13 |\r\n",
      "|   NA | False |       NA | NA       | \"FP\"          |  44203 |\r\n",
      "|   NA | False |       NA | NA       | \"TP\"          | 183245 |\r\n",
      "|   NA |  True |    False | \"FP\"     | \"FP\"          |    615 |\r\n",
      "|   NA |  True |    False | \"FP\"     | \"TP\"          |      3 |\r\n",
      "|   NA |  True |     True | \"FP\"     | \"FP\"          |  31691 |\r\n",
      "|   NA |  True |     True | \"FP\"     | \"TP\"          |     87 |\r\n",
      "+------+-------+----------+----------+---------------+--------+\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:30:02,726 - INFO - Running 5-annotate_ht_after_rf.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 3-variant_qc/5-annotate_ht_after_rf.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1230-0.2.133-4c60fddb171a.log\r\n",
      "2025-02-27 12:30:21.531 Hail: INFO: Reading table without type imputation1) / 1]\r\n",
      "  Loading field 'f0' as type str (user-supplied)\r\n",
      "  Loading field 'f1' as type int32 (user-supplied)\r\n",
      "  Loading field 'f2' as type str (user-supplied)\r\n",
      "  Loading field 'f3' as type str (user-supplied)\r\n",
      "  Loading field 'f4' as type str (user-supplied)\r\n",
      "  Loading field 'f5' as type str (user-supplied)\r\n",
      "2025-02-27 12:30:24.863 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:30:32.865 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/test-run-model/rf_result_with_synonymous.ht\r\n",
      "=== Annotating with family stats and DNMs ===\r\n",
      "2025-02-27 12:30:34.427 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:30:40.849 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/test-run-model/rf_result_denovo_family_stats.ht\r\n",
      "Annotating with transmitted singletons\r\n",
      "2025-02-27 12:30:42.769 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:30:49.503 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "[Stage 13:======================================>                   (2 + 1) / 3]\r\n",
      "Transmitted singletons:4231\r\n",
      "\r\n",
      "\r\n",
      "Untransmitted singletons:4400\r\n",
      "\r\n",
      "\r\n",
      "Trans/Untrans ratio:0.961590909090909\r\n",
      "\r\n",
      "2025-02-27 12:30:55.026 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "[Stage 16:======================================>                   (2 + 1) / 3]\r\n",
      "579395 records.\r\n",
      "\r\n",
      "- variant_transmitted_singletons (int64):\r\n",
      "  Non-missing: 579395 (100.00%)\r\n",
      "      Missing: 0\r\n",
      "      Minimum: 0\r\n",
      "      Maximum: 1\r\n",
      "         Mean: 0.01\r\n",
      "      Std Dev: 0.09\r\n",
      "2025-02-27 12:31:00.422 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "[Stage 19:>                                                         (0 + 3) / 3]\r\n",
      "579395 records.\r\n",
      "\r\n",
      "- variant_untransmitted_singletons (int64):\r\n",
      "  Non-missing: 579395 (100.00%)\r\n",
      "      Missing: 0\r\n",
      "      Minimum: 0\r\n",
      "      Maximum: 1\r\n",
      "         Mean: 0.01\r\n",
      "      Std Dev: 0.09\r\n",
      "2025-02-27 12:31:05.835 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:31:06.720 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:31:07.347 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:31:16.705 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/test-run-model/rf_result_trans_sing.ht\r\n",
      "=== Annotating with gnomad AF ===\r\n",
      "2025-02-27 12:31:18.797 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:31:19.419 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:31:19.995 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:38:13.531 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/test-run-model/rf_result_final_for_ranking.ht\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:38:14,721 - INFO - Running 6-rank_and_bin.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 3-variant_qc/6-rank_and_bin.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1238-0.2.133-4c60fddb171a.log\r\n",
      "=== Assigning ranks ===\r\n",
      "2025-02-27 12:38:35.019 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:38:41.539 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_TablegtbECTK1VE\r\n",
      "2025-02-27 12:38:45.249 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:38:50.777 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/tmp/persist_TablefKlUt1sqvA\r\n",
      "2025-02-27 12:38:55.036 Hail: INFO: wrote table with 579395 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/test-run-model/rf_result_ranked.ht\r\n",
      "=== Ranking results and adding bins ===\r\n",
      "Found the following variant counts:                                 (1 + 2) / 3]\r\n",
      " Struct(rank={'indel': 75877, 'snv': 503518},\r\n",
      "       singleton_rank={'indel': 476, 'snv': 6931},\r\n",
      "       biallelic_rank={'indel': 37846, 'snv': 491585},\r\n",
      "       biallelic_singleton_rank={'indel': 476, 'snv': 6931},\r\n",
      "       de_novo_high_quality_rank={'indel': 315, 'snv': 172},\r\n",
      "       de_novo_medium_quality_rank={'indel': 344, 'snv': 181},\r\n",
      "       de_novo_synonymous_rank={'snv': 78577})\r\n",
      "2025-02-27 12:39:21.365 Hail: INFO: wrote table with 1203229 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/test-run-model/_gnomad_score_binning_tmp.ht\r\n",
      "2025-02-27 12:39:32.470 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:39:41.234 Hail: INFO: wrote table with 24613 rows in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/variant_qc_random_forest/test-run-model/_rf_result_ranked_BINS.ht\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:39:42,536 - INFO - Running 7-plot_rf_output.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 3-variant_qc/7-plot_rf_output.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1239-0.2.133-4c60fddb171a.log\r\n",
      "2025-02-27 12:40:02.778 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:314: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:314: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:330: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:330: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:346: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0] / x[1],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:346: RuntimeWarning: invalid value encountered in scalar divide\r\n",
      "  y_fun=lambda x: x[0] / x[1],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:346: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0] / x[1],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:363: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:363: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:378: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:378: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:393: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0] / x[1],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:393: RuntimeWarning: invalid value encountered in scalar divide\r\n",
      "  y_fun=lambda x: x[0] / x[1],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:393: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0] / x[1],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:409: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:409: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:425: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:425: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:441: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0] / x[1],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:441: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0] / x[1],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:457: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:457: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:473: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:473: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:489: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:489: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:505: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:505: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:521: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:521: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:537: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:537: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function sum at 0x7f9acf77b550> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function min at 0x7f9acf77bca0> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:216: FutureWarning: The provided callable <function max at 0x7f9acf77bb80> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\r\n",
      "  df = df.groupby([\"model\", \"bin\"]).agg(\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:553: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:195: FutureWarning: The provided callable <function cumsum at 0x7f9acf77b8b0> is currently using SeriesGroupBy.cumsum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"cumsum\" instead.\r\n",
      "  df[f\"{col}_cumul\"] = df.groupby(\"model\")[col].aggregate(np.cumsum)\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:553: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\r\n",
      "  y_fun=lambda x: x[0],\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n",
      "/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/3-variant_qc/7-plot_rf_output.py:19: UserWarning: \r\n",
      "You are attempting to set `plot.legend.label_text_font_size` on a plot that has zero legends added, this will have no effect.\r\n",
      "\r\n",
      "Before legend properties can be set, you must add a Legend explicitly, or call a glyph method with a legend parameter set.\r\n",
      "\r\n",
      "  p.legend.label_text_font_size = qc_plots_settings[\"label_text_font_size\"]\r\n",
      "BokehDeprecationWarning: CDSView.source is no longer needed, and is now ignored. In a future release, passing source will result an error.\r\n",
      "BokehDeprecationWarning: CDSView.filters was deprecated in bokeh 3.0. Use CDSView.filter instead.\r\n"
     ]
    }
   ],
   "source": [
    "step3_2 = {\n",
    "    \"4-apply_rf.py\": \"3-4-apply-rf\",\n",
    "    \"5-annotate_ht_after_rf.py\": \"3-5-annotate-ht-after-rf\",\n",
    "    \"6-rank_and_bin.py\": \"3-6-rank-and-bin\",\n",
    "    \"7-plot_rf_output.py\": \"3-7-plot-rf-output\",\n",
    "}\n",
    "step3_folder = \"3-variant_qc\"\n",
    "run_step_scripts(step3_folder, step3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Genotype QC\n",
    "\n",
    "To perform genotype QC, you need to determine the best combination of hard filters,\n",
    "to save \"good\" variations as much as possible,\n",
    "and get rid of all \"bad\" variants and genotypes at the same time.\n",
    "\n",
    "The first script of the genotype QC helps you to analyze different combinations of hard filters\n",
    "and choose optimal values.\n",
    "\n",
    "Please refer to the docs for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T12:44:09.660341Z",
     "start_time": "2025-02-27T12:42:33.785173Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:42:33,787 - INFO - Running 1-compare_hard_filter_combinations.py --all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 4-genotype_qc/1-compare_hard_filter_combinations.py --all\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/4-genotype_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/4-genotype_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1242-0.2.133-4c60fddb171a.log\r\n",
      "=== Preparing control GIAB sample ===\r\n",
      "INFO:root:Preparing GiaB HailTable\r\n",
      "2025-02-27 12:42:52.751 Hail: INFO: Reading table without type imputation1) / 1]\r\n",
      "  Loading field 'f0' as type str (not specified)\r\n",
      "  Loading field 'f1' as type int32 (user-supplied)\r\n",
      "  Loading field 'f2' as type str (not specified)\r\n",
      "  Loading field 'f3' as type str (not specified)\r\n",
      "  Loading field 'f4' as type str (not specified)\r\n",
      "  Loading field 'f5' as type str (not specified)\r\n",
      "  Loading field 'f6' as type str (not specified)\r\n",
      "  Loading field 'f7' as type str (not specified)\r\n",
      "2025-02-27 12:42:56.497 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:42:56.863 Hail: INFO: scanning VCF for sortedness...\r\n",
      "2025-02-27 12:43:00.159 Hail: INFO: VCF is out of order...          (0 + 1) / 1]\r\n",
      "  Write the dataset to disk before running multiple queries to avoid multiple costly data shuffles.\r\n",
      "2025-02-27 12:43:01.885 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:43:12.290 Hail: INFO: wrote table with 66599 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/HG001_GRCh38_benchmark.interval.illumina.ht\r\n",
      "=== Annotating matrix table with RF bins ===\r\n",
      "2025-02-27 12:43:13.723 Hail: INFO: Reading table without type imputation\r\n",
      "  Loading field 'f0' as type str (not specified)\r\n",
      "  Loading field 'f1' as type int32 (user-supplied)\r\n",
      "  Loading field 'f2' as type str (not specified)\r\n",
      "  Loading field 'f3' as type str (not specified)\r\n",
      "  Loading field 'f4' as type str (not specified)\r\n",
      "  Loading field 'f5' as type str (not specified)\r\n",
      "2025-02-27 12:43:17.169 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 12:43:36.851 Hail: INFO: wrote matrix table with 579395 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/test-run-model/tmp.hard_filters_combs.mt\r\n",
      "=== Calculating hard filter evaluation for SNV ===\r\n",
      "2025-02-27 12:43:39.507 Hail: INFO: wrote table with 59520 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/test-run-model/giab_table.snv.ht\r\n",
      "=== Starting parameter combination evaluation: 6 combinations ===\r\n",
      "=== Starting evaluation for snv ===\r\n",
      "2025-02-27 12:43:44.291 Hail: INFO: wrote matrix table with 503518 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/test-run-model/tmp.hard_filters_combs_snv.bin.1.mt\r\n",
      "=== Processing snv bin: 80 ===\r\n",
      "2025-02-27 12:43:48.015 Hail: INFO: wrote matrix table with 402800 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/test-run-model/tmp.hard_filters_combs_snv.bin.2.mt\r\n",
      "--- Testing snv hard filter combination: bin=80 DP=5 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_5 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/snv_hardfilters_bin_80_DP_5_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 1/6 completed.\r\n",
      "--- Spend 0 days (0.002 hr) to process 1 steps\r\n",
      "--- Estimated to complete: 0 days and 0.01 hr.\r\n",
      "--- Testing snv hard filter combination: bin=80 DP=10 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_10 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/snv_hardfilters_bin_80_DP_10_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 2/6 completed.\r\n",
      "--- Spend 0 days (0.002 hr) to process 2 steps\r\n",
      "--- Estimated to complete: 0 days and 0.00 hr.\r\n",
      "=== Processing snv bin: 60 ===\r\n",
      "2025-02-27 12:43:51.604 Hail: INFO: wrote matrix table with 302100 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/test-run-model/tmp.hard_filters_combs_snv.bin.1.mt\r\n",
      "--- Testing snv hard filter combination: bin=60 DP=5 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_5 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/snv_hardfilters_bin_60_DP_5_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 3/6 completed.\r\n",
      "--- Spend 0 days (0.003 hr) to process 3 steps\r\n",
      "--- Estimated to complete: 0 days and 0.00 hr.\r\n",
      "--- Testing snv hard filter combination: bin=60 DP=10 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_10 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/snv_hardfilters_bin_60_DP_10_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 4/6 completed.\r\n",
      "--- Spend 0 days (0.003 hr) to process 4 steps\r\n",
      "--- Estimated to complete: 0 days and 0.00 hr.\r\n",
      "=== Processing snv bin: 40 ===\r\n",
      "2025-02-27 12:43:54.556 Hail: INFO: wrote matrix table with 201400 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/test-run-model/tmp.hard_filters_combs_snv.bin.2.mt\r\n",
      "--- Testing snv hard filter combination: bin=40 DP=5 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_5 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/snv_hardfilters_bin_40_DP_5_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 5/6 completed.\r\n",
      "--- Spend 0 days (0.004 hr) to process 5 steps\r\n",
      "--- Estimated to complete: 0 days and 0.00 hr.\r\n",
      "--- Testing snv hard filter combination: bin=40 DP=10 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_10 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/snv_hardfilters_bin_40_DP_10_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 6/6 completed.\r\n",
      "--- Spend 0 days (0.004 hr) to process 6 steps\r\n",
      "--- Estimated to complete: 0 days and 0.00 hr.\r\n",
      "=== Calculating total TP and FP for snv ===\r\n",
      "=== SNV evaluation competed successfully.\r\n",
      "Execution time: 18.34 seconds ===\r\n",
      "=== Calculating hard filter evaluation for InDels ===\r\n",
      "2025-02-27 12:43:57.520 Hail: INFO: wrote table with 7077 rows in 1 partition to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/test-run-model/giab_table.indel.ht\r\n",
      "=== Starting parameter combination evaluation: 6 combinations ===\r\n",
      "=== Starting evaluation for indel ===\r\n",
      "2025-02-27 12:44:00.426 Hail: INFO: wrote matrix table with 75877 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/test-run-model/tmp.hard_filters_combs_indel.bin.1.mt\r\n",
      "=== Processing indel bin: 75 ===\r\n",
      "2025-02-27 12:44:02.687 Hail: INFO: wrote matrix table with 56850 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/test-run-model/tmp.hard_filters_combs_indel.bin.2.mt\r\n",
      "--- Testing indel hard filter combination: bin=75 DP=5 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_5 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/indel_hardfilters_bin_75_DP_5_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 1/6 completed.\r\n",
      "--- Spend 0 days (0.001 hr) to process 1 steps\r\n",
      "--- Estimated to complete: 0 days and 0.01 hr.\r\n",
      "--- Testing indel hard filter combination: bin=75 DP=10 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_10 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/indel_hardfilters_bin_75_DP_10_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 2/6 completed.\r\n",
      "--- Spend 0 days (0.001 hr) to process 2 steps\r\n",
      "--- Estimated to complete: 0 days and 0.00 hr.\r\n",
      "=== Processing indel bin: 50 ===\r\n",
      "2025-02-27 12:44:04.850 Hail: INFO: wrote matrix table with 37900 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/test-run-model/tmp.hard_filters_combs_indel.bin.1.mt\r\n",
      "--- Testing indel hard filter combination: bin=50 DP=5 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_5 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/indel_hardfilters_bin_50_DP_5_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 3/6 completed.\r\n",
      "--- Spend 0 days (0.002 hr) to process 3 steps\r\n",
      "--- Estimated to complete: 0 days and 0.00 hr.\r\n",
      "--- Testing indel hard filter combination: bin=50 DP=10 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_10 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/indel_hardfilters_bin_50_DP_10_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 4/6 completed.\r\n",
      "--- Spend 0 days (0.002 hr) to process 4 steps\r\n",
      "--- Estimated to complete: 0 days and 0.00 hr.\r\n",
      "=== Processing indel bin: 25 ===\r\n",
      "2025-02-27 12:44:07.144 Hail: INFO: wrote matrix table with 18950 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/test-run-model/tmp.hard_filters_combs_indel.bin.2.mt\r\n",
      "--- Testing indel hard filter combination: bin=25 DP=5 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_5 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/indel_hardfilters_bin_25_DP_5_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 5/6 completed.\r\n",
      "--- Spend 0 days (0.003 hr) to process 5 steps\r\n",
      "--- Estimated to complete: 0 days and 0.00 hr.\r\n",
      "--- Testing indel hard filter combination: bin=25 DP=10 GQ=10 AB=0.2 call_rate=0.5\r\n",
      "INFO:root:DP_10 GQ_10 AB_0.2 missing_0.5\r\n",
      "--- Checkpoint data loaded from file /lustre/scratch126/teams/hgi/gz3/public-dataset/annotations/test-run-model/json_dump/indel_hardfilters_bin_25_DP_10_GQ_10_AB_0.2_missing_0.5.json\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "--- Step 6/6 completed.\r\n",
      "--- Spend 0 days (0.003 hr) to process 6 steps\r\n",
      "--- Estimated to complete: 0 days and 0.00 hr.\r\n",
      "=== Calculating total TP and FP for indel ===\r\n",
      "=== INDEL evaluation competed successfully.\r\n",
      "Execution time: 12.33 seconds ===\r\n",
      "=== Plotting hard filter combinations ===\r\n",
      "--- Generating interactive plot recall vs precision in /lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.snv.precision_recall.html, ---\r\n",
      "INFO:bokeh.io.state:Session output file '/lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.snv.precision_recall.html' already exists, will be overwritten.\r\n",
      "--- Generating interactive plot FP vs TP in /lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.snv.tp_fp.html, ---\r\n",
      "INFO:bokeh.io.state:Session output file '/lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.snv.tp_fp.html' already exists, will be overwritten.\r\n",
      "--- Generating interactive plot mendelian_error_mean vs TP in /lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.snv.tp_mendel.html, ---\r\n",
      "INFO:bokeh.io.state:Session output file '/lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.snv.tp_mendel.html' already exists, will be overwritten.\r\n",
      "--- Generating interactive plot t_u_ratio vs TP in /lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.snv.tp_t_u_ratio.html, ---\r\n",
      "INFO:bokeh.io.state:Session output file '/lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.snv.tp_t_u_ratio.html' already exists, will be overwritten.\r\n",
      "--- Generating interactive plot FP vs TP in /lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.indel.tp_fp.html, ---\r\n",
      "INFO:bokeh.io.state:Session output file '/lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.indel.tp_fp.html' already exists, will be overwritten.\r\n",
      "--- Generating interactive plot mendelian_error_mean vs TP in /lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.indel.tp_mendel.html, ---\r\n",
      "INFO:bokeh.io.state:Session output file '/lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.indel.tp_mendel.html' already exists, will be overwritten.\r\n",
      "--- Generating interactive plot recall vs precision in /lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.indel.precision_recall.html, ---\r\n",
      "INFO:bokeh.io.state:Session output file '/lustre/scratch126/teams/hgi/gz3/public-dataset/plots/hard_filter_evaluation.indel.precision_recall.html' already exists, will be overwritten.\r\n",
      "=== Plotting hard filter combinations completed successfully ===\r\n",
      "INFO:py4j.clientserver:Closing down clientserver connection\r\n"
     ]
    }
   ],
   "source": [
    "step4_1 = {\n",
    "    \"1-compare_hard_filter_combinations.py --all\": \"4-1-compare-hard-filter-combinations\",\n",
    "}\n",
    "step4_folder = \"4-genotype_qc\"\n",
    "run_step_scripts(step4_folder, step4_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this step, you MUST review and analyze the results to choose correct values for hardfilter combinations**.\n",
    "The values for the public datasets are not suitable for your data.\n",
    "Please refer to the docs for details: `docs/wes-qc-hail.md`.\n",
    "\n",
    "After choosing the hard filters, you can run the last part of the data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T14:11:26.811824Z",
     "start_time": "2025-02-27T13:55:11.460033Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 13:55:11,461 - INFO - Running 2-apply_range_of_hard_filters.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 4-genotype_qc/2-apply_range_of_hard_filters.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/4-genotype_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/4-genotype_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1355-0.2.133-4c60fddb171a.log\r\n",
      "2025-02-27 13:55:30.657 Hail: INFO: Reading table without type imputation1) / 1]\r\n",
      "  Loading field 'f0' as type str (user-supplied)\r\n",
      "  Loading field 'f1' as type int32 (user-supplied)\r\n",
      "  Loading field 'f2' as type str (user-supplied)\r\n",
      "  Loading field 'f3' as type str (user-supplied)\r\n",
      "  Loading field 'f4' as type str (user-supplied)\r\n",
      "  Loading field 'f5' as type str (user-supplied)\r\n",
      "  Loading field 'f6' as type str (user-supplied)\r\n",
      "  Loading field 'f7' as type str (user-supplied)\r\n",
      "  Loading field 'f8' as type str (user-supplied)\r\n",
      "2025-02-27 13:55:44.245 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 13:55:48.339 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 13:55:50.075 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 13:55:51.631 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "2025-02-27 14:01:19.223 Hail: INFO: wrote matrix table with 579395 rows and 104 columns in 3 partitions to file:///lustre/scratch126/teams/hgi/gz3/public-dataset/matrixtables/mt_hard_filter_combinations.mt\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 14:01:20,490 - INFO - Running 3a-export_vcfs_range_of_hard_filters.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 4-genotype_qc/3a-export_vcfs_range_of_hard_filters.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/4-genotype_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/4-genotype_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1401-0.2.133-4c60fddb171a.log\r\n",
      "Exporting chr1\r\n",
      "2025-02-27 14:01:34.553 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:02:00.169 Hail: INFO: merging 4 files totalling 46.9M... + 1) / 3]\r\n",
      "2025-02-27 14:02:01.373 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr1_hard_filters.vcf.bgz\r\n",
      "  merge time: 1.203s\r\n",
      "Exporting chr2\r\n",
      "2025-02-27 14:02:01.425 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:02:15.811 Hail: INFO: merging 4 files totalling 32.7M... + 2) / 3]\r\n",
      "2025-02-27 14:02:16.550 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr2_hard_filters.vcf.bgz\r\n",
      "  merge time: 738.722ms\r\n",
      "Exporting chr3\r\n",
      "2025-02-27 14:02:16.616 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:02:31.672 Hail: INFO: merging 4 files totalling 25.5M... + 2) / 3]\r\n",
      "2025-02-27 14:02:32.336 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr3_hard_filters.vcf.bgz\r\n",
      "  merge time: 663.390ms\r\n",
      "Exporting chr4\r\n",
      "2025-02-27 14:02:32.376 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:02:43.418 Hail: INFO: merging 4 files totalling 18.4M... + 1) / 3]\r\n",
      "2025-02-27 14:02:43.839 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr4_hard_filters.vcf.bgz\r\n",
      "  merge time: 421.184ms\r\n",
      "Exporting chr5\r\n",
      "2025-02-27 14:02:43.876 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:02:55.153 Hail: INFO: merging 4 files totalling 20.6M... + 2) / 3]\r\n",
      "2025-02-27 14:02:55.595 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr5_hard_filters.vcf.bgz\r\n",
      "  merge time: 441.265ms\r\n",
      "Exporting chr6\r\n",
      "2025-02-27 14:02:55.636 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:03:07.289 Hail: INFO: merging 4 files totalling 25.3M... + 1) / 3]\r\n",
      "2025-02-27 14:03:07.667 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr6_hard_filters.vcf.bgz\r\n",
      "  merge time: 377.587ms\r\n",
      "Exporting chr7\r\n",
      "2025-02-27 14:03:07.703 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:03:19.230 Hail: INFO: merging 4 files totalling 22.0M... + 1) / 3]\r\n",
      "2025-02-27 14:03:19.630 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr7_hard_filters.vcf.bgz\r\n",
      "  merge time: 400.202ms\r\n",
      "Exporting chr8\r\n",
      "2025-02-27 14:03:19.676 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:03:31.413 Hail: INFO: merging 4 files totalling 16.4M... + 1) / 3]\r\n",
      "2025-02-27 14:03:31.858 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr8_hard_filters.vcf.bgz\r\n",
      "  merge time: 443.939ms\r\n",
      "Exporting chr9\r\n",
      "2025-02-27 14:03:31.895 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:03:42.761 Hail: INFO: merging 4 files totalling 19.4M... + 2) / 3]\r\n",
      "2025-02-27 14:03:43.121 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr9_hard_filters.vcf.bgz\r\n",
      "  merge time: 358.492ms\r\n",
      "Exporting chr10\r\n",
      "2025-02-27 14:03:43.170 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:03:54.237 Hail: INFO: merging 4 files totalling 19.6M... + 1) / 3]\r\n",
      "2025-02-27 14:03:54.638 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr10_hard_filters.vcf.bgz\r\n",
      "  merge time: 400.969ms\r\n",
      "Exporting chr11\r\n",
      "2025-02-27 14:03:54.676 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:04:07.180 Hail: INFO: merging 4 files totalling 27.3M... + 2) / 3]\r\n",
      "2025-02-27 14:04:07.758 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr11_hard_filters.vcf.bgz\r\n",
      "  merge time: 577.688ms\r\n",
      "Exporting chr12\r\n",
      "2025-02-27 14:04:07.798 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:04:19.700 Hail: INFO: merging 4 files totalling 24.7M... + 2) / 3]\r\n",
      "2025-02-27 14:04:20.210 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr12_hard_filters.vcf.bgz\r\n",
      "  merge time: 509.912ms\r\n",
      "Exporting chr13\r\n",
      "2025-02-27 14:04:20.272 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:04:28.759 Hail: INFO: merging 4 files totalling 8.4M...2 + 1) / 3]\r\n",
      "2025-02-27 14:04:28.956 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr13_hard_filters.vcf.bgz\r\n",
      "  merge time: 196.498ms\r\n",
      "Exporting chr14\r\n",
      "2025-02-27 14:04:28.992 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:04:38.019 Hail: INFO: merging 4 files totalling 15.8M... + 1) / 3]\r\n",
      "2025-02-27 14:04:38.306 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr14_hard_filters.vcf.bgz\r\n",
      "  merge time: 287.382ms\r\n",
      "Exporting chr15\r\n",
      "2025-02-27 14:04:38.342 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:04:48.449 Hail: INFO: merging 4 files totalling 15.1M... + 1) / 3]\r\n",
      "2025-02-27 14:04:48.746 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr15_hard_filters.vcf.bgz\r\n",
      "  merge time: 296.743ms\r\n",
      "Exporting chr16\r\n",
      "2025-02-27 14:04:48.794 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:05:01.540 Hail: INFO: merging 4 files totalling 20.0M... + 2) / 3]\r\n",
      "2025-02-27 14:05:01.993 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr16_hard_filters.vcf.bgz\r\n",
      "  merge time: 452.998ms\r\n",
      "Exporting chr17\r\n",
      "2025-02-27 14:05:02.042 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:05:14.314 Hail: INFO: merging 4 files totalling 26.7M... + 2) / 3]\r\n",
      "2025-02-27 14:05:14.892 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr17_hard_filters.vcf.bgz\r\n",
      "  merge time: 577.620ms\r\n",
      "Exporting chr18\r\n",
      "2025-02-27 14:05:14.934 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:05:24.016 Hail: INFO: merging 4 files totalling 7.3M...2 + 1) / 3]\r\n",
      "2025-02-27 14:05:24.175 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr18_hard_filters.vcf.bgz\r\n",
      "  merge time: 158.548ms\r\n",
      "Exporting chr19\r\n",
      "2025-02-27 14:05:24.218 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:05:37.568 Hail: INFO: merging 4 files totalling 31.8M... + 2) / 3]\r\n",
      "2025-02-27 14:05:38.206 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr19_hard_filters.vcf.bgz\r\n",
      "  merge time: 637.684ms\r\n",
      "Exporting chr20\r\n",
      "2025-02-27 14:05:38.251 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:05:47.376 Hail: INFO: merging 4 files totalling 12.4M... + 1) / 3]\r\n",
      "2025-02-27 14:05:47.606 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr20_hard_filters.vcf.bgz\r\n",
      "  merge time: 229.807ms\r\n",
      "Exporting chr21\r\n",
      "2025-02-27 14:05:47.657 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:05:55.580 Hail: INFO: merging 4 files totalling 5.7M...2 + 1) / 3]\r\n",
      "2025-02-27 14:05:55.700 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr21_hard_filters.vcf.bgz\r\n",
      "  merge time: 120.366ms\r\n",
      "Exporting chr22\r\n",
      "2025-02-27 14:05:55.737 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:06:04.301 Hail: INFO: merging 4 files totalling 11.0M... + 1) / 3]\r\n",
      "2025-02-27 14:06:04.538 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chr22_hard_filters.vcf.bgz\r\n",
      "  merge time: 236.951ms\r\n",
      "Exporting chrX\r\n",
      "2025-02-27 14:06:04.576 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:06:13.170 Hail: INFO: merging 4 files totalling 9.7M...2 + 1) / 3]\r\n",
      "2025-02-27 14:06:13.414 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chrX_hard_filters.vcf.bgz\r\n",
      "  merge time: 243.944ms\r\n",
      "Exporting chrY\r\n",
      "2025-02-27 14:06:13.453 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "2025-02-27 14:06:20.448 Hail: INFO: merging 4 files totalling 24.2K... + 1) / 3]\r\n",
      "2025-02-27 14:06:20.495 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations/chrY_hard_filters.vcf.bgz\r\n",
      "  merge time: 46.973ms\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 14:06:21,605 - INFO - Running 3b-export_vcfs_stingent_filters.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 4-genotype_qc/3b-export_vcfs_stingent_filters.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/4-genotype_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/4-genotype_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1406-0.2.133-4c60fddb171a.log\r\n",
      "Exporting chr1\r\n",
      "2025-02-27 14:06:34.882 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:06:56.007 Hail: INFO: merging 4 files totalling 34.9M... + 1) / 3]\r\n",
      "2025-02-27 14:06:56.866 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr1_stringent_filters.vcf.bgz\r\n",
      "  merge time: 856.669ms\r\n",
      "Exporting chr2\r\n",
      "2025-02-27 14:06:56.952 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:07:09.261 Hail: INFO: merging 4 files totalling 24.6M... + 1) / 3]\r\n",
      "2025-02-27 14:07:09.727 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr2_stringent_filters.vcf.bgz\r\n",
      "  merge time: 466.066ms\r\n",
      "Exporting chr3\r\n",
      "2025-02-27 14:07:09.774 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:07:22.603 Hail: INFO: merging 4 files totalling 19.8M... + 2) / 3]\r\n",
      "2025-02-27 14:07:23.028 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr3_stringent_filters.vcf.bgz\r\n",
      "  merge time: 424.887ms\r\n",
      "Exporting chr4\r\n",
      "2025-02-27 14:07:23.069 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:07:34.260 Hail: INFO: merging 4 files totalling 14.1M... + 2) / 3]\r\n",
      "2025-02-27 14:07:34.542 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr4_stringent_filters.vcf.bgz\r\n",
      "  merge time: 281.620ms\r\n",
      "Exporting chr5\r\n",
      "2025-02-27 14:07:34.581 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:07:45.041 Hail: INFO: merging 4 files totalling 15.8M... + 1) / 3]\r\n",
      "2025-02-27 14:07:45.370 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr5_stringent_filters.vcf.bgz\r\n",
      "  merge time: 327.912ms\r\n",
      "Exporting chr6\r\n",
      "2025-02-27 14:07:45.411 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:07:56.020 Hail: INFO: merging 4 files totalling 18.6M... + 1) / 3]\r\n",
      "2025-02-27 14:07:56.377 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr6_stringent_filters.vcf.bgz\r\n",
      "  merge time: 356.766ms\r\n",
      "Exporting chr7\r\n",
      "2025-02-27 14:07:56.435 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:08:06.601 Hail: INFO: merging 4 files totalling 15.8M... + 2) / 3]\r\n",
      "2025-02-27 14:08:06.884 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr7_stringent_filters.vcf.bgz\r\n",
      "  merge time: 282.493ms\r\n",
      "Exporting chr8\r\n",
      "2025-02-27 14:08:06.926 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:08:16.745 Hail: INFO: merging 4 files totalling 12.5M... + 1) / 3]\r\n",
      "2025-02-27 14:08:16.999 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr8_stringent_filters.vcf.bgz\r\n",
      "  merge time: 253.997ms\r\n",
      "Exporting chr9\r\n",
      "2025-02-27 14:08:17.048 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:08:28.354 Hail: INFO: merging 4 files totalling 14.6M... + 2) / 3]\r\n",
      "2025-02-27 14:08:28.662 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr9_stringent_filters.vcf.bgz\r\n",
      "  merge time: 306.943ms\r\n",
      "Exporting chr10\r\n",
      "2025-02-27 14:08:28.704 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:08:38.685 Hail: INFO: merging 4 files totalling 14.8M... + 1) / 3]\r\n",
      "2025-02-27 14:08:38.967 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr10_stringent_filters.vcf.bgz\r\n",
      "  merge time: 281.565ms\r\n",
      "Exporting chr11\r\n",
      "2025-02-27 14:08:39.011 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:08:49.616 Hail: INFO: merging 4 files totalling 20.3M... + 2) / 3]\r\n",
      "2025-02-27 14:08:49.990 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr11_stringent_filters.vcf.bgz\r\n",
      "  merge time: 374.131ms\r\n",
      "Exporting chr12\r\n",
      "2025-02-27 14:08:50.052 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:09:00.678 Hail: INFO: merging 4 files totalling 18.5M... + 2) / 3]\r\n",
      "2025-02-27 14:09:00.997 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr12_stringent_filters.vcf.bgz\r\n",
      "  merge time: 319.222ms\r\n",
      "Exporting chr13\r\n",
      "2025-02-27 14:09:01.049 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:09:09.304 Hail: INFO: merging 4 files totalling 6.3M...2 + 1) / 3]\r\n",
      "2025-02-27 14:09:09.417 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr13_stringent_filters.vcf.bgz\r\n",
      "  merge time: 112.909ms\r\n",
      "Exporting chr14\r\n",
      "2025-02-27 14:09:09.455 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:09:18.742 Hail: INFO: merging 4 files totalling 11.3M... + 1) / 3]\r\n",
      "2025-02-27 14:09:18.957 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr14_stringent_filters.vcf.bgz\r\n",
      "  merge time: 214.568ms\r\n",
      "Exporting chr15\r\n",
      "2025-02-27 14:09:18.995 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:09:28.328 Hail: INFO: merging 4 files totalling 11.5M... + 1) / 3]\r\n",
      "2025-02-27 14:09:28.526 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr15_stringent_filters.vcf.bgz\r\n",
      "  merge time: 197.976ms\r\n",
      "Exporting chr16\r\n",
      "2025-02-27 14:09:28.567 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:09:38.371 Hail: INFO: merging 4 files totalling 14.7M... + 2) / 3]\r\n",
      "2025-02-27 14:09:38.656 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr16_stringent_filters.vcf.bgz\r\n",
      "  merge time: 284.880ms\r\n",
      "Exporting chr17\r\n",
      "2025-02-27 14:09:38.698 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:09:49.464 Hail: INFO: merging 4 files totalling 19.8M... + 2) / 3]\r\n",
      "2025-02-27 14:09:49.966 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr17_stringent_filters.vcf.bgz\r\n",
      "  merge time: 500.857ms\r\n",
      "Exporting chr18\r\n",
      "2025-02-27 14:09:50.009 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:09:57.896 Hail: INFO: merging 4 files totalling 5.6M...2 + 1) / 3]\r\n",
      "2025-02-27 14:09:58.035 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr18_stringent_filters.vcf.bgz\r\n",
      "  merge time: 138.627ms\r\n",
      "Exporting chr19\r\n",
      "2025-02-27 14:09:58.074 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:10:09.550 Hail: INFO: merging 4 files totalling 21.6M... + 2) / 3]\r\n",
      "2025-02-27 14:10:09.968 Hail: INFO: while writing:==================(3 + 1) / 3]\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr19_stringent_filters.vcf.bgz\r\n",
      "  merge time: 417.560ms\r\n",
      "Exporting chr20\r\n",
      "2025-02-27 14:10:10.012 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:10:19.284 Hail: INFO: merging 4 files totalling 9.5M...2 + 1) / 3]\r\n",
      "2025-02-27 14:10:19.517 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr20_stringent_filters.vcf.bgz\r\n",
      "  merge time: 232.212ms\r\n",
      "Exporting chr21\r\n",
      "2025-02-27 14:10:19.560 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:10:27.172 Hail: INFO: merging 4 files totalling 4.2M...2 + 1) / 3]\r\n",
      "2025-02-27 14:10:27.259 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr21_stringent_filters.vcf.bgz\r\n",
      "  merge time: 86.780ms\r\n",
      "Exporting chr22\r\n",
      "2025-02-27 14:10:27.303 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:10:35.844 Hail: INFO: merging 4 files totalling 7.9M...2 + 1) / 3]\r\n",
      "2025-02-27 14:10:35.988 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chr22_stringent_filters.vcf.bgz\r\n",
      "  merge time: 143.464ms\r\n",
      "Exporting chrX\r\n",
      "2025-02-27 14:10:36.055 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:10:44.235 Hail: INFO: merging 4 files totalling 6.6M...2 + 1) / 3]\r\n",
      "2025-02-27 14:10:44.380 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chrX_stringent_filters.vcf.bgz\r\n",
      "  merge time: 144.383ms\r\n",
      "Exporting chrY\r\n",
      "2025-02-27 14:10:44.418 Hail: WARN: export_vcf: ignored the following fields:\r\n",
      "    'chromosome' (global)\r\n",
      "    'meanHetAB' (row)\r\n",
      "    'stringent_AN' (row)\r\n",
      "    'stringent_AC' (row)\r\n",
      "    'stringent_AC_Hom' (row)\r\n",
      "    'stringent_AC_Het' (row)\r\n",
      "    'medium_AN' (row)\r\n",
      "    'medium_AC' (row)\r\n",
      "    'medium_AC_Hom' (row)\r\n",
      "    'medium_AC_Het' (row)\r\n",
      "    'relaxed_AN' (row)\r\n",
      "    'relaxed_AC' (row)\r\n",
      "    'relaxed_AC_Hom' (row)\r\n",
      "    'relaxed_AC_Het' (row)\r\n",
      "2025-02-27 14:10:51.077 Hail: INFO: merging 4 files totalling 22.0K... + 1) / 3]\r\n",
      "2025-02-27 14:10:51.125 Hail: INFO: while writing:\r\n",
      "    file:///lustre/scratch126/teams/hgi/gz3/public-dataset/vcf_afterqc_export/filtered_vcfs_combinations_stringent/chrY_stringent_filters.vcf.bgz\r\n",
      "  merge time: 47.824ms\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 14:10:52,244 - INFO - Running 5-mutation-spectra_afterqc.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "\n",
      "Running the job with spark-submit\r\n",
      "spark-submit 4-genotype_qc/5-mutation-spectra_afterqc.py\r\n",
      "info: script_dir  /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/4-genotype_qc\r\n",
      "Loading config '/lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/4-genotype_qc/../config/inputs.yaml', default\r\n",
      "=== Cleaning up temporary folder /lustre/scratch126/teams/hgi/gz3/public-dataset/tmp\r\n",
      "=== Initializing Hail ===\r\n",
      "Running on Apache Spark version 3.5.3\r\n",
      "SparkUI available at http://spark-master:4040\r\n",
      "Welcome to\r\n",
      "     __  __     <>__\r\n",
      "    / /_/ /__  __/ /\r\n",
      "   / __  / _ `/ / /\r\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.133-4c60fddb171a\r\n",
      "LOGGING: writing to /lustre/scratch126/teams/hgi/gz3/wes_qc_pycharm/hail-20250227-1410-0.2.133-4c60fddb171a.log\r\n",
      "2025-02-27 14:11:05.863 Hail: WARN: entries(): Resulting entries table is sorted by '(row_key, col_key)'.\r\n",
      "    To preserve row-major matrix table order, first unkey columns with 'key_cols_by()'\r\n",
      "2025-02-27 14:11:16.323 Hail: INFO: Ordering unsorted dataset with network shuffle\r\n",
      "[Stage 2:===========================================================(3 + 1) / 3]\r"
     ]
    }
   ],
   "source": [
    "step4_2 = {\n",
    "    \"2-apply_range_of_hard_filters.py\": \"4-2-apply-range-of-hard-filters\",\n",
    "    \"3a-export_vcfs_range_of_hard_filters.py\": \"4-3a-export-vcfs-range-of-hard-filters\",\n",
    "    \"3b-export_vcfs_stingent_filters.py\": \"4-3b-export-vcfs-stingent-filters\",\n",
    "    \"5-mutation-spectra_afterqc.py\": \"4-5-mutation-spectra_afterqc\",\n",
    "}\n",
    "step4_folder = \"4-genotype_qc\"\n",
    "run_step_scripts(step4_folder, step4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hail",
   "language": "python",
   "name": "hail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
