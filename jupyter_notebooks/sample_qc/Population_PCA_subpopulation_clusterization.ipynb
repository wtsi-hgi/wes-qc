{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc714f8-35a6-47b6-9116-47d917d4f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "import pyspark\n",
    "from hail.plot import show\n",
    "import bokeh\n",
    "from bokeh.plotting import output_file, save\n",
    "import umap\n",
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from gnomad.sample_qc.ancestry import pc_project\n",
    "from gnomad.sample_qc.ancestry import assign_population_pcs\n",
    "import hdbscan\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "############################\n",
    "# specify temporary folder #\n",
    "############################\n",
    "tmp_dir = \"file:///lustre/scratch126/teams/hgi/users/vo3/tmp/\"\n",
    "\n",
    "#initiate hail\n",
    "hl.stop()\n",
    "hl.init(sc=sc, tmp_dir=tmp_dir, default_reference=\"GRCh38\")\n",
    "hl.plot.output_notebook()\n",
    "tmp_file = \"/lustre/scratch123/projects/gnh_industry/Genes_and_Health_2024_03_54k/qc/plots/tmp.html\"#temp file for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3e3b5-9d06-4dc8-b60d-788c9f4efafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca(mt: hl.MatrixTable, n: int):\n",
    "    #runs PCA and adds some columns to one of the tables so PC projection can be made\n",
    "    pca_evals, pca_scores, pca_loadings = hl.hwe_normalized_pca(mt.GT, k=n, compute_loadings=True)\n",
    "    pca_af_ht = mt.annotate_rows(pca_af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2).rows()\n",
    "    pca_loadings = pca_loadings.annotate(pca_af=pca_af_ht[pca_loadings.key].pca_af)\n",
    "    return pca_evals, pca_scores, pca_loadings\n",
    "\n",
    "def pc_projection(mt: hl.MatrixTable, pca_scores: hl.Table, pca_loadings: hl.Table):\n",
    "    #projects samples on PCs and then combines PCA_scores tables\n",
    "    projection_PCA_scores=pc_project(mt, pca_loadings, loading_location='loadings', af_location='pca_af')\n",
    "    union_PCA_scores=pca_scores.union(projection_PCA_scores)\n",
    "    return union_PCA_scores\n",
    "\n",
    "def UMAP_run (pca: hl.Table, df: pandas.DataFrame, n: int):\n",
    "    #creates a data frame used for plotting to separate populations\n",
    "    reducer = umap.UMAP()\n",
    "    scores = pandas.DataFrame.from_records(pca.to_pandas().scores)\n",
    "    embedding = reducer.fit_transform(scores[range(n)])\n",
    "    embedding.shape\n",
    "    sns_data = pandas.DataFrame(embedding)\n",
    "    sns_data['s'] = pca.s.collect()\n",
    "    sns_data=pandas.merge(sns_data, df, left_on='s', right_on='Sample_ID', how='left')\n",
    "    return sns_data\n",
    "\n",
    "def filter_mt (pcamt: hl.MatrixTable):\n",
    "    #1 Remove palindromes, no other filters\n",
    "    mt_non_pal = pcamt.filter_rows((pcamt.alleles[0] == \"G\") & (pcamt.alleles[1] == \"C\"), keep=False)\n",
    "    mt_non_pal = mt_non_pal.filter_rows((mt_non_pal.alleles[0] == \"C\") & (mt_non_pal.alleles[1] == \"G\"), keep=False)\n",
    "    mt_non_pal = mt_non_pal.filter_rows((mt_non_pal.alleles[0] == \"A\") & (mt_non_pal.alleles[1] == \"T\"), keep=False)\n",
    "    pcamt_filtered1 = mt_non_pal.filter_rows((mt_non_pal.alleles[0] == \"T\") & (mt_non_pal.alleles[1] == \"A\"), keep=False)\n",
    "\n",
    "    #2 Remove palindromes and filter without MAF\n",
    "    mt_vqc = hl.variant_qc(pcamt_filtered1, name='variant_QC_Hail')\n",
    "    pcamt_filtered2 = mt_vqc.filter_rows(\n",
    "        (mt_vqc.variant_QC_Hail.call_rate >= 0.99) &\n",
    "        (mt_vqc.variant_QC_Hail.p_value_hwe >= 1e-5)\n",
    "    )\n",
    "    #3 Remove palindromes and filter with MAF\n",
    "    pcamt_filtered3 = pcamt_filtered2.filter_rows(pcamt_filtered2.variant_QC_Hail.AF[1] >= 0.05)\n",
    "\n",
    "    return pcamt_filtered1, pcamt_filtered2, pcamt_filtered3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6e51b-b4bb-4344-b4bf-fac35e7c0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folders with hail matrices and tables\n",
    "mtdir=\"file:///lustre/scratch123/projects/gnh_industry/Genes_and_Health_2024_03_54k/qc/matrixtables/\"\n",
    "mtdir2=\"/lustre/scratch123/projects/gnh_industry/Genes_and_Health_2024_03_54k/qc/matrixtables/\"\n",
    "\n",
    "#files\n",
    "pruned_mt_file=mtdir+\"mt_ldpruned.mt\"#result of 2-sample_qc/2-prune_related_samples.py\n",
    "samples_to_remove_file=mtdir+\"mt_related_samples_to_remove.ht\"#result of 2-sample_qc/2-prune_related_samples.py\n",
    "\n",
    "#files to save information about PCA of unrelated samples\n",
    "pca_scores_file_UR = mtdir+\"pca_scores.unrelated.ht\"\n",
    "pca_loadings_file_UR = mtdir+\"pca_loadings.unrelated.ht\"\n",
    "pca_evals_file_UR = mtdir2+\"pca_evals.unrelated.txt\"\n",
    "\n",
    "#file to save information about union of PCA of unrelated samples and prokjected related samples\n",
    "union_pca_scores_file= mtdir+\"pca_scores.union.ht\"\n",
    "\n",
    "#matrix with 1000G samples\n",
    "kg_mt_file = mtdir + \"/kg_wes_regions.mt\"\n",
    "\n",
    "#file with information about samples from 1000 Genomes\n",
    "pops_file = \"file:///lustre/scratch123/projects/gnh_industry/Genes_and_Health_2024_03_54k/qc/igsr_samples.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9458e-bf42-4093-a706-2193a4c16e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean pruned matrix from unneeded rows and get a list(table) of related samples\n",
    "pruned_mt = hl.read_matrix_table(pruned_mt_file)\n",
    "pruned_mt = pruned_mt.drop('callrate', 'f_stat', 'is_female')\n",
    "related_samples_to_remove = hl.read_table(samples_to_remove_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ebd52",
   "metadata": {},
   "source": [
    "# WARNING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318684a6-d5b1-4057-895c-9eba645c40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "###########################################\n",
    "#               Be careful!               #\n",
    "#   Don't run it like this if you have    #\n",
    "#      pop_assignments.superpop.ht        #\n",
    "#   you don't wan't to change this file   #\n",
    "###########################################\n",
    "'''\n",
    "\n",
    "pop_file=mtdir+\"pop_assignments.ht\"#result of 2-sample_qc/3-population_pca_prediction.py\n",
    "super_pop_file=mtdir+\"pop_assignments.superpop.ht\"#table with assigned superpopulation\n",
    "'''\n",
    "###########################################\n",
    "#               WARNING!                  #\n",
    "#   if pop_assignments.superpop.ht exist  #\n",
    "#       comment the next two lines        #\n",
    "#       and uncoment the last line        #\n",
    "###########################################\n",
    "'''\n",
    "pop_ht=hl.read_table(pop_file)\n",
    "pop_ht.write(super_pop_file, overwrite=True)\n",
    "\n",
    "#pop_ht=hl.read_table(pop_assisuper_pop_filegnments.superpop.ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cdd264-cfb8-4361-8752-e9f590592119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rmove samples not assigned to SAS superpopulation\n",
    "non_sas_to_remove=pop_ht.filter((pop_ht.pop!='SAS') & (hl.is_missing(pop_ht.known_pop)))\n",
    "pca_mt = pruned_mt.filter_cols(hl.is_defined(non_sas_to_remove[pruned_mt.col_key]), keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455028a-2d78-4d84-b971-fa26f1ef8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# optional step to add SAS samples from 1000G #\n",
    "###############################################\n",
    "\n",
    "kg_mt = hl.read_matrix_table(kg_mt_file)\n",
    "\n",
    "kg_mt = kg_mt.select_entries(kg_mt.GT)\n",
    "\n",
    "cohorts_pop = hl.import_table(pops_file, delimiter=\"\\t\").key_by('Sample name')\n",
    "kg_mt = kg_mt.annotate_cols(known_pop=cohorts_pop[kg_mt.s]['Superpopulation code'])\n",
    "kg_sas_mt=kg_mt.filter_cols(kg_mt.known_pop=='SAS')\n",
    "kg_sas_mt = kg_sas_mt.drop('known_pop')\n",
    "\n",
    "mt_joined = pca_mt.union_cols(kg_sas_mt)\n",
    "mt_joined = mt_joined.annotate_cols(known_pop=cohorts_pop[mt_joined.s]['Superpopulation code'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20564681-4134-4125-a70b-f6d1e6e9ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply 3 filters to the matrix\n",
    "pca_mt_filtered1, pca_mt_filtered2, pca_mt_filtered3 = filter_mt(pca_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d6911-c803-436e-bb11-93f24f58bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# optional apply 3 filters to the matrix with SAS #\n",
    "###################################################\n",
    "pca_mt_kg_filtered1, pca_mt_kg_filtered2, pca_mt_kg_filtered3 = filter_mt(mt_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91962a51-07cf-485c-8606-6152bed1479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate related and unrelated samples\n",
    "pca_mt1_UR = pca_mt_filtered1.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_filtered1.col_key]), keep=False)\n",
    "pca_mt1_R = pca_mt_filtered1.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_filtered1.col_key]))\n",
    "\n",
    "pca_mt2_UR = pca_mt_filtered2.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_filtered2.col_key]), keep=False)\n",
    "pca_mt2_R = pca_mt_filtered2.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_filtered2.col_key]))\n",
    "\n",
    "pca_mt3_UR = pca_mt_filtered3.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_filtered3.col_key]), keep=False)\n",
    "pca_mt3_R = pca_mt_filtered3.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_filtered3.col_key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7feab4c-59e1-4331-8665-260f86baf5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# optional separation of ELGH sampls and 1000G SAS samples #\n",
    "############################################################\n",
    "pca_mt1_kg_UR = pca_mt_kg_filtered1.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_kg_filtered1.col_key]), keep=False)\n",
    "pca_mt1_kg_R = pca_mt_kg_filtered1.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_kg_filtered1.col_key]))\n",
    "\n",
    "pca_mt2_kg_UR = pca_mt_kg_filtered2.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_kg_filtered2.col_key]), keep=False)\n",
    "pca_mt2_kg_R = pca_mt_kg_filtered2.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_kg_filtered2.col_key]))\n",
    "\n",
    "pca_mt3_kg_UR = pca_mt_kg_filtered3.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_kg_filtered3.col_key]), keep=False)\n",
    "pca_mt3_kg_R = pca_mt_kg_filtered3.filter_cols(hl.is_defined(related_samples_to_remove[pca_mt_kg_filtered3.col_key]))\n",
    "\n",
    "pca_mt1_sas = pca_mt1_kg_UR.filter_cols(hl.is_defined(pca_mt1_kg_UR.known_pop))\n",
    "pca_mt1_kg_UR = pca_mt1_kg_UR.filter_cols(hl.is_missing(pca_mt1_kg_UR.known_pop))\n",
    "\n",
    "pca_mt2_sas = pca_mt2_kg_UR.filter_cols(hl.is_defined(pca_mt2_kg_UR.known_pop))\n",
    "pca_mt2_kg_UR = pca_mt2_kg_UR.filter_cols(hl.is_missing(pca_mt2_kg_UR.known_pop))\n",
    "\n",
    "pca_mt3_sas = pca_mt3_kg_UR.filter_cols(hl.is_defined(pca_mt3_kg_UR.known_pop))\n",
    "pca_mt3_kg_UR = pca_mt3_kg_UR.filter_cols(hl.is_missing(pca_mt3_kg_UR.known_pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74b989-297f-40a3-a36f-7d58674530cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run PCA for unrelated samples\n",
    "print(\"PCA1\")\n",
    "pca_evals1, pca_scores1, pca_loadings1 = run_pca(pca_mt1_UR, 10)\n",
    "print(\"PCA2\")\n",
    "pca_evals2, pca_scores2, pca_loadings2 = run_pca(pca_mt2_UR, 10)\n",
    "print(\"PCA3\")\n",
    "pca_evals3, pca_scores3, pca_loadings3 = run_pca(pca_mt3_UR, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbcc6a5-5f38-47f1-b14e-a2509c6ad7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tmp PCA files\n",
    "tmp_dir2=tmp_dir.replace('file://', '')\n",
    "\n",
    "pca_scores_fileX = tmp_dir + \"pca_scores1.ht\"\n",
    "pca_loadings_fileX = tmp_dir + \"pca_loadings1.ht\"\n",
    "pca_evals_fileX = tmp_dir2 + \"pca_evals1.txt\"\n",
    "\n",
    "pca_scores1.write(pca_scores_fileX, overwrite=True)\n",
    "pca_loadings1.write(pca_loadings_fileX, overwrite=True)\n",
    "with open(pca_evals_fileX, 'w') as f:\n",
    "    for val in pca_evals1:\n",
    "        f.write(str(val) + \"\\n\")\n",
    "\n",
    "pca_scores_fileX = tmp_dir + \"pca_scores2.ht\"\n",
    "pca_loadings_fileX = tmp_dir + \"pca_loadings2.ht\"\n",
    "pca_evals_fileX = tmp_dir2 + \"pca_evals2.txt\"\n",
    "\n",
    "pca_scores2.write(pca_scores_fileX, overwrite=True)\n",
    "pca_loadings2.write(pca_loadings_fileX, overwrite=True)\n",
    "with open(pca_evals_fileX, 'w') as f:\n",
    "    for val in pca_evals2:\n",
    "        f.write(str(val) + \"\\n\")\n",
    "\n",
    "pca_scores_fileX = tmp_dir + \"pca_scores3.ht\"\n",
    "pca_loadings_fileX = tmp_dir + \"pca_loadings3.ht\"\n",
    "pca_evals_fileX = tmp_dir2 + \"pca_evals3.txt\"\n",
    "\n",
    "pca_scores3.write(pca_scores_fileX, overwrite=True)\n",
    "pca_loadings3.write(pca_loadings_fileX, overwrite=True)\n",
    "with open(pca_evals_fileX, 'w') as f:\n",
    "    for val in pca_evals3:\n",
    "        f.write(str(val) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27a4e0-657f-4ecb-b345-3dec0378ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# optional PCA for ELGH samples which were combined with 1000G SAS samples #\n",
    "############################################################################\n",
    "print(\"PCA1\")\n",
    "pca_kg_evals1, pca_kg_scores1, pca_kg_loadings1 = run_pca(pca_mt1_kg_UR, 10)\n",
    "print(\"PCA2\")\n",
    "pca_kg_evals2, pca_kg_scores2, pca_kg_loadings2 = run_pca(pca_mt2_kg_UR, 10)\n",
    "print(\"PCA3\")\n",
    "pca_kg_evals3, pca_kg_scores3, pca_kg_loadings3 = run_pca(pca_mt3_kg_UR, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d8445-b7c4-4f8e-8a30-713e8f123229",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "# optional save tmp PCA files for ELGH samples which were combined with 1000G SAS samples #\n",
    "###########################################################################################\n",
    "pca_scores_fileX = tmp_dir + \"pca_scores1_1kg.ht\"\n",
    "pca_loadings_fileX = tmp_dir + \"pca_loadings1_1kg.ht\"\n",
    "pca_evals_fileX = tmp_dir2 + \"pca_evals1_1kg.txt\"\n",
    "\n",
    "pca_kg_scores1.write(pca_scores_fileX, overwrite=True)\n",
    "pca_kg_loadings1.write(pca_loadings_fileX, overwrite=True)\n",
    "with open(pca_evals_fileX, 'w') as f:\n",
    "    for val in pca_kg_evals1:\n",
    "        f.write(str(val) + \"\\n\")\n",
    "\n",
    "pca_scores_fileX = tmp_dir + \"pca_scores2_1kg.ht\"\n",
    "pca_loadings_fileX = tmp_dir + \"pca_loadings2_1kg.ht\"\n",
    "pca_evals_fileX = tmp_dir2 + \"pca_evals2_1kg.txt\"\n",
    "\n",
    "pca_kg_scores2.write(pca_scores_fileX, overwrite=True)\n",
    "pca_kg_loadings2.write(pca_loadings_fileX, overwrite=True)\n",
    "with open(pca_evals_fileX, 'w') as f:\n",
    "    for val in pca_kg_evals2:\n",
    "        f.write(str(val) + \"\\n\")\n",
    "\n",
    "pca_scores_fileX = tmp_dir + \"pca_scores3_1kg.ht\"\n",
    "pca_loadings_fileX = tmp_dir + \"pca_loadings3_1kg.ht\"\n",
    "pca_evals_fileX = tmp_dir2 + \"pca_evals3_1kg.txt\"\n",
    "\n",
    "pca_kg_scores3.write(pca_scores_fileX, overwrite=True)\n",
    "pca_kg_loadings3.write(pca_loadings_fileX, overwrite=True)\n",
    "with open(pca_evals_fileX, 'w') as f:\n",
    "    for val in pca_kg_evals3:\n",
    "        f.write(str(val) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make data frames for plots\n",
    "sns_data1 = pandas.DataFrame.from_records(pca_scores1.to_pandas().scores)[range(5)]\n",
    "sns_data1['s'] = pca_scores1.s.collect()\n",
    "\n",
    "sns_data2 = pandas.DataFrame.from_records(pca_scores2.to_pandas().scores)[range(5)]\n",
    "sns_data2['s'] = pca_scores2.s.collect()\n",
    "\n",
    "sns_data3 = pandas.DataFrame.from_records(pca_scores3.to_pandas().scores)[range(5)]\n",
    "sns_data3['s'] = pca_scores3.s.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e48f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# optional for ELGH sampls and 1000G SAS samples       #\n",
    "############################################################\n",
    "sns_data1_kg = pandas.DataFrame.from_records(pca_kg_scores1.to_pandas().scores)[range(5)]\n",
    "sns_data1_kg['s'] = pca_kg_scores1.s.collect()\n",
    "\n",
    "sns_data2_kg = pandas.DataFrame.from_records(pca_kg_scores2.to_pandas().scores)[range(5)]\n",
    "sns_data2_kg['s'] = pca_kg_scores2.s.collect()\n",
    "\n",
    "sns_data3_kg = pandas.DataFrame.from_records(pca_kg_scores3.to_pandas().scores)[range(5)]\n",
    "sns_data3_kg['s'] = pca_kg_scores3.s.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a pandas dataframe with self-reported ethnicity for each sample\n",
    "ethnic_file='/path/to/file/with_SR_wthnicity.tsv'\n",
    "ethnic_df=pandas.read_csv(ethnic_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7283d-3a1a-4aa3-8f8c-f97d77e001e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotates dataframes\n",
    "sns_data1=pandas.merge(sns_data1, ethnic_df, left_on='s', right_on='Sample_ID', how='left')\n",
    "sns_data2=pandas.merge(sns_data2, ethnic_df, left_on='s', right_on='Sample_ID', how='left')\n",
    "sns_data3=pandas.merge(sns_data3, ethnic_df, left_on='s', right_on='Sample_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3cf347",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# optional for ELGH sampls and 1000G SAS samples #\n",
    "##################################################\n",
    "sns_data1_kg=pandas.merge(sns_data1_kg, ethnic_df, left_on='s', right_on='Sample_ID', how='left')\n",
    "sns_data2_kg=pandas.merge(sns_data2_kg, ethnic_df, left_on='s', right_on='Sample_ID', how='left')\n",
    "sns_data3_kg=pandas.merge(sns_data3_kg, ethnic_df, left_on='s', right_on='Sample_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbbc66-202b-4fcf-a067-2df653db297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = seaborn.pairplot(sns_data1, vars=sns_data1.columns[range(5)], hue='SR_Ethnicity',  plot_kws={'s':2})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd0ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = seaborn.pairplot(sns_data2, vars=sns_data2.columns[range(5)], hue='SR_Ethnicity',  plot_kws={'s':2})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8fa8b-1c9b-4534-bf69-2855ecd395ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = seaborn.pairplot(sns_data3, vars=sns_data3.columns[range(5)], hue='SR_Ethnicity',  plot_kws={'s':2})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional\n",
    "p = seaborn.pairplot(sns_data1_kg, vars=sns_data1.columns[range(5)], hue='SR_Ethnicity',  plot_kws={'s':2})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015bd52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional\n",
    "p = seaborn.pairplot(sns_data2_kg, vars=sns_data1.columns[range(5)], hue='SR_Ethnicity',  plot_kws={'s':2})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad453325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional\n",
    "p = seaborn.pairplot(sns_data3_kg, vars=sns_data1.columns[range(5)], hue='SR_Ethnicity',  plot_kws={'s':2})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1df03e-5359-44c4-be45-a6174b8ddd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose prefered filtration\n",
    "pca_evals_UR=pca_evals1\n",
    "pca_scores_UR=pca_scores1\n",
    "pca_loadings_UR=pca_loadings1\n",
    "pca_mt_R=pca_mt1_R\n",
    "\n",
    "pca_scores_file_UR = mtdir + \"pca_scores.unrelated_test2.ht\"\n",
    "pca_loadings_file_UR = mtdir + \"pca_loadings.unrelated_test2.ht\"\n",
    "pca_evals_file_UR = mtdir2 + \"pca_evals.unrelated_test2.txt\"\n",
    "union_pca_scores_file= mtdir+\"pca_scores.union_test2.ht\"\n",
    "\n",
    "pca_scores_UR.write(pca_scores_file_UR, overwrite=True)\n",
    "pca_loadings_UR.write(pca_loadings_file_UR, overwrite=True)\n",
    "with open(pca_evals_file_UR, 'w') as f:\n",
    "    for val in pca_evals_UR:\n",
    "        f.write(str(val) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a09f171-9ee4-4716-b0f5-58f9563f7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# optional selection of SAS matrix according to filter selection #\n",
    "##################################################################\n",
    "SAS_mt=pca_mt1_sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c44cc-2863-4018-9c9e-3e844d78dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#project related samples on PC of unrelated samples and unite them\n",
    "union_PCA_scores=pc_projection(pca_mt_R, pca_scores_UR, pca_loadings_UR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023348c-34d6-43a2-afff-ff0c45fcfe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# optional projection and union with SAS #\n",
    "##########################################\n",
    "union_PCA_scores=pc_projection(SAS_mt, union_PCA_scores, pca_loadings_UR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc215c-da80-4d57-8e81-8cb0c310242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save PCA scores\n",
    "union_PCA_scores.write(union_pca_scores_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26c111-2471-41e1-8a2b-60615d3a5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe for a plot\n",
    "sns_data = pandas.DataFrame.from_records(union_PCA_scores.to_pandas().scores)[range(5)]\n",
    "sns_data['s'] = union_PCA_scores.s.collect()\n",
    "sns_data=pandas.merge(sns_data, ethnic_df, left_on='s', right_on='Sample_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee1dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# optional annotation if added 1000G #\n",
    "######################################\n",
    "sns_data['SR_Ethnicity'] = sns_data['SR_Ethnicity'].fillna('SAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d92b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a plot\n",
    "p = seaborn.pairplot(sns_data, vars=sns_data.columns[range(5)], hue='SR_Ethnicity',  plot_kws={'s':2})\n",
    "#plt.savefig(\"PCA_scores_pairplot.Self_reported_ethnicity.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96825172-9041-44f1-8a1d-5685ae4c311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# optional get population names from 1000 genomes #\n",
    "###################################################\n",
    "pops_file2 = \"/lustre/scratch123/projects/gnh_industry/Genes_and_Health_2024_03_54k/qc/igsr_samples.tsv\"\n",
    "kgpop=pandas.read_csv(pops_file2, sep='\\t')\n",
    "kgpop=kgpop[[\"Sample name\", \"Population name\"]]\n",
    "kgpop = kgpop.rename(columns={'Sample name': 's',\n",
    "                        'Population name': 'Known_pop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba003b7c-c5b9-49e2-868a-79fc7944f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# optional annotate df with population names from 1000 genomes #\n",
    "################################################################\n",
    "sns_data=pandas.merge(sns_data, kgpop, on='s', how='left')\n",
    "sns_data['Known_pop'] = sns_data['Known_pop'].fillna('ELGH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2cf25-3967-43a3-ae57-dec92d353af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# optional plot with names from 1000 genomes #\n",
    "###################################################\n",
    "p = seaborn.pairplot(sns_data, vars=sns_data.columns[range(5)], hue='Known_pop',  plot_kws={'s':2})\n",
    "#plt.savefig(\"PCA_scores_pairplot.Self_reported_ethnicity.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0e161-e591-4f05-8933-c8b2d802f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "################################################\n",
    "# The next steps can be repeated several times #\n",
    "#         with different number of PCs         #\n",
    "################################################\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e06d135-2969-4cf1-8fe4-7b9434eb3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make datframe to divide samples into populations\n",
    "#specify the number of PCs\n",
    "sns_data_UM=UMAP_run(union_PCA_scores, ethnic_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd644c-0fe3-49b9-9516-cc9bc24d2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# optional annotation of the datframe #\n",
    "#######################################\n",
    "sns_data_UM=pandas.merge(sns_data_UM, kgpop, on='s', how='left')\n",
    "sns_data_UM['Known_pop'] = sns_data_UM['Known_pop'].fillna('ELGH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456699eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#umap plot with self-reported ethnicity\n",
    "p = seaborn.scatterplot(data=sns_data_UM, \n",
    "                       x=0, y=1, hue='SR_Ethnicity')\n",
    "#plt.savefig(\"PCA_UMAP.Self_reported_ethnicity.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7487a5a-18dd-4fdd-b1a3-8f58f3156781",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# optional plot with ethnicity from 1000 genomes #\n",
    "##################################################\n",
    "p = seaborn.scatterplot(data=sns_data_UM, \n",
    "                       x=0, y=1, hue='Known_pop')\n",
    "#plt.savefig(\"PCA_UMAP.ethnicity_from_1K_genomes.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceef457-a2e6-4df3-955c-36d3ebe5b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify clusters\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=1000, min_samples=1000)\n",
    "sns_data_cluster=sns_data_UM[[0,1]]\n",
    "clusterer.fit(sns_data_cluster)\n",
    "sns_data_UM['label'] = clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8227dfe-6d9c-4923-9a29-327fa9543ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#umap plot with clusters\n",
    "p = seaborn.scatterplot(data=sns_data_UM, \n",
    "                       x=0, y=1, hue='label')\n",
    "#plt.savefig(\"PCA_UMAP.nPCs.OG_clusters.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394155a1-8890-4e60-be0b-745fc02f322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify clusters\n",
    "sns_data_UM2=sns_data_UM.copy()\n",
    "sns_data_UM2.loc[sns_data_UM2[0] < 4, 'label'] = 0\n",
    "sns_data_UM2.loc[sns_data_UM2[0] >= 4, 'label'] = 1\n",
    "sns_data_UM2.loc[((sns_data_UM2[0] >2.5) & (sns_data_UM2[1] <-4.3)), 'label'] = 1\n",
    "sns_data_UM2.loc[((sns_data_UM2[0] >2.3) & (sns_data_UM2[1] >15)), 'label'] = 1\n",
    "sns_data_UM2.loc[((sns_data_UM2[0] >2.3) & (sns_data_UM2[1] >15)), 'label'] = 1\n",
    "sns_data_UM2.loc[((sns_data_UM2[0] <0) & (sns_data_UM2[1] <-5)), 'label'] = -1\n",
    "sns_data_UM2.loc[((sns_data_UM2[0] <2.5) & (sns_data_UM2[1] <17)& (sns_data_UM2[1] >13)), 'label'] = -1\n",
    "sns_data_UM2.loc[((sns_data_UM2[0] <1) & (sns_data_UM2[1] <14) & (sns_data_UM2[1] >10)), 'label'] = 0\n",
    "\n",
    "p = seaborn.scatterplot(data=sns_data_UM2,\n",
    "                       x=0, y=1, hue='label')\n",
    "#plt.savefig(\"UMAP.no_palindrome.3PCs.clusters.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb445a0d-cb8c-44bc-8bfe-cf78ec84c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename clusters\n",
    "sns_data_UM2['label']=sns_data_UM2['label'].astype(str).replace('1', 'bangladeshi').replace('0', 'pakistani').replace('-1', 'other-sas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95625e2-2764-4eeb-a16f-840cc1ae06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#umap plot with renamed clusters\n",
    "p = seaborn.scatterplot(data=sns_data_UM2, \n",
    "                       x=0, y=1, hue='label')\n",
    "#plt.savefig(\"UMAP.no_palindrome.3PCs.clusters2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fa304-b64a-4f16-94a2-1e6373e1568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine samples with non-sas and combine annotation\n",
    "sns_data_UM2=sns_data_UM2.drop(columns=[0, 1, \"Sample_ID\", \"SR_Ethnicity\"])\n",
    "non_sas_df=non_sas_to_remove.to_pandas()\n",
    "non_sas=non_sas_df.drop(columns=[\"known_pop\", \"pca_scores\", \"prob_AFR\", \"prob_AMR\", \"prob_EAS\", \"prob_EUR\", \"prob_SAS\", \"evaluation_sample\", \"training_sample\"])\n",
    "non_sas['pop']='non-sas'\n",
    "pop_df=pandas.concat([sns_data_UM2, non_sas])\n",
    "pop_df['label'] = pop_df['label'].fillna(pop_df['pop'])\n",
    "pop_df=pop_df.reset_index().drop(columns=['index', 'pop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da974d-dad3-4dcd-8ec0-afedb6fa1612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with information from pop_ht and new poppulation annotation\n",
    "popht_df=pop_ht.to_pandas()\n",
    "popht_df=pandas.merge(popht_df, pop_df, on='s', how='left')\n",
    "popht_df['label'] = popht_df['label'].fillna(popht_df['pop'])\n",
    "popht_df['pop']=popht_df['label']\n",
    "popht_df=popht_df.drop(columns=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c2ffcb-fc79-4d94-92c7-668fb89b5013",
   "metadata": {},
   "source": [
    "#WARNING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "###########################################\n",
    "#                Be careful!              #\n",
    "#            You rewrite a table          #\n",
    "#   that was created by previous script.  #\n",
    "#         you should have superpop ht     #\n",
    "#              before running this        #\n",
    "###########################################\n",
    "'''\n",
    "#save new poppulation information in hail table\n",
    "ht_pop = hl.Table.from_pandas(popht_df)\n",
    "pop_file=mtdir+\"pop_assignments.ht\"\n",
    "ht_pop.write(pop_file, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
